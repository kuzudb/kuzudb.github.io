<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Scaling Pytorch Geometric GNNs With KÃ¹zu | KÃ¹zu</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" property="og:url" content="https://kuzudb.com/docusaurus/blog/kuzu-pyg-remote-backend"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="og:locale" content="en_US"><meta data-rh="true" name="og:type" content="article"><meta data-rh="true" name="og:site_name" content="KÃ¹zu"><meta data-rh="true" name="og:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="twitter:site" content="@kuzudb"><meta data-rh="true" name="twitter:creator" content="@kuzudb"><meta data-rh="true" name="twitter:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" property="og:title" content="Scaling Pytorch Geometric GNNs With KÃ¹zu | KÃ¹zu"><meta data-rh="true" name="description" content="In this post, we&#x27;ll walk through how to use KÃ¹zu as a Pytorch Geometric (PyG) Remote Backend to train a GNN model on very large graphs that do not fit on your machine&#x27;s RAM."><meta data-rh="true" property="og:description" content="In this post, we&#x27;ll walk through how to use KÃ¹zu as a Pytorch Geometric (PyG) Remote Backend to train a GNN model on very large graphs that do not fit on your machine&#x27;s RAM."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-05-10T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.linkedin.com/in/mewim/,https://cs.uwaterloo.ca/~ssalihog/"><meta data-rh="true" property="article:tag" content="use-case"><link data-rh="true" rel="icon" href="/docusaurus/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://kuzudb.com/docusaurus/blog/kuzu-pyg-remote-backend"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog/kuzu-pyg-remote-backend" hreflang="en"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog/kuzu-pyg-remote-backend" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XV0PE3XW33-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/docusaurus/blog/rss.xml" title="KÃ¹zu RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/docusaurus/blog/atom.xml" title="KÃ¹zu Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="KÃ¹zu" href="/docusaurus/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer"><link rel="stylesheet" href="/docusaurus/assets/css/styles.6fd37a31.css">
<link rel="preload" href="/docusaurus/assets/js/runtime~main.044b3ffa.js" as="script">
<link rel="preload" href="/docusaurus/assets/js/main.6b97b9f5.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://kuzudb.com/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/docusaurus/img/kuzu-logo.png" alt="KÃ¹zu" class="themedImage_ToTc themedImage--light_HNdA"><img src="/docusaurus/img/kuzu-logo-inverse.png" alt="KÃ¹zu" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/docusaurus/installation">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docusaurus/blog/">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item">
            <a href="https://github.com/kuzudb/kuzu" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-github fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://discord.gg/jw7xN2ZhJB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-discord fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://twitter.com/kuzudb" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-twitter fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://www.youtube.com/@KuzuDB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-youtube fa-xl"></i>
            </a>
            </div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.2.0-release">KÃ¹zu 0.2.0 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/transforming-your-data-to-graphs-1">Transforming your data to graphs - Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-2">RAG Using Unstructured Data &amp; Role of Knowledge Graphs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-1">RAG Using Structured Data: Overview &amp; Important Questions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.1.0-release">KÃ¹zu 0.1.0 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.12-release">KÃ¹zu 0.0.12 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzuexplorer">KÃ¹zuExplorer: Visualizing Query Results and Schemas</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.11-release">KÃ¹zu 0.0.11 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.10-release">KÃ¹zu 0.0.10 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.9-release">KÃ¹zu 0.0.9 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.8-release">KÃ¹zu 0.0.8 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.7-release">KÃ¹zu 0.0.7 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/iamgraphviz">IAMGraphViz: Visualizing AWS IAM Permissions with KÃ¹zu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.6-release">KÃ¹zu 0.0.6 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.5-release">KÃ¹zu 0.0.5 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.4-release">KÃ¹zu 0.0.4 Release</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/docusaurus/blog/kuzu-pyg-remote-backend">Scaling Pytorch Geometric GNNs With KÃ¹zu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.3-release">KÃ¹zu 0.0.3 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/wcoj">Why (Graph) DBMSs Need New Join Algorithms: The Story of Worst-case Optimal Join Algorithms</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.2-release">KÃ¹zu 0.0.2 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/factorization">Factorization &amp; Great Ideas from Database Theory</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/what-every-gdbms-should-do-and-vision">What Every Competent GDBMS Should Do (aka The Goals &amp; Vision of KÃ¹zu)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/meet-kuzu">Meet KÃ¹zu ðŸ¤—</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">Scaling Pytorch Geometric GNNs With KÃ¹zu</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-05-10T00:00:00.000Z" itemprop="datePublished">May 10, 2023</time> Â· <!-- -->13 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/mewim/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/chang.gif" alt="Chang Liu"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/mewim/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Chang Liu</span></a></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/semih.jpg" alt="Semih SalihoÄŸlu"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Semih SalihoÄŸlu</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of KÃ¹zu Inc. &amp; Associate Prof. at UWaterloo</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p>In this post, we&#x27;ll walk through how to use KÃ¹zu as a <a href="https://pytorch-geometric.readthedocs.io/en/latest/advanced/remote.html" target="_blank" rel="noopener noreferrer">Pytorch Geometric (PyG) <em>Remote Backend</em></a> to train a GNN model on very large graphs that do not fit on your machine&#x27;s RAM. </p><p>Let&#x27;s start with a quick overview of PyG Remote Backends: PyG Remote Backends are plug-in replacements for PyG&#x27;s in-memory graph and feature stores, so they can be used seamlessly with the rest of the PyG interfaces to develop your GNN models. If a PyG Remote Backend is a disk-based storage system, such as KÃ¹zu, PyG will fetch subgraphs from KÃ¹zu, which stores and scans its data from disk, allowing you to train models on very large graphs for which PyG&#x27;s in-memory storage would run out of memory and fail.</p><p>As you&#x27;ll see, if you already have PyG models you have developed in Python, replacing PyG&#x27;s default storage with KÃ¹zu is extremely simple. <strong><em>It
consists of loading your graph into KÃ¹zu and then changing 1 line of code in your PyG model</em></strong>. To demonstrate how simple this is and how it performs,
se will follow this <a href="https://github.com/pyg-team/pytorch_geometric/tree/master/examples/kuzu/papers_100M" target="_blank" rel="noopener noreferrer">Sample Code</a> to demonstrate how to do this.
So let&#x27;s get to it!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-predictive-task-and-gnn-model">Dataset, Predictive Task, and GNN Model<a href="#dataset-predictive-task-and-gnn-model" class="hash-link" aria-label="Direct link to Dataset, Predictive Task, and GNN Model" title="Direct link to Dataset, Predictive Task, and GNN Model">â€‹</a></h2><p>Let&#x27;s start by describing our graph dataset, our predictive task, and the GNN model we will use for the predictive task.</p><p><strong>Dataset</strong>: We will use the <code>ogbn-papers100M</code> dataset of ~100M nodes and ~2.5B edges from the <a href="https://ogb.stanford.edu/" target="_blank" rel="noopener noreferrer">Open Graph Benchmark</a> (OGB). To find the dataset,
you can search for &quot;ogbn-papers100M&quot; <a href="https://ogb.stanford.edu/docs/nodeprop/" target="_blank" rel="noopener noreferrer">here</a>. The dataset takes about 128GB of RAM when using PyG&#x27;s default in-memory storage. The graph&#x27;s nodes and edges model the following:</p><p><em>Nodes</em> are papers that have these properties:</p><ul><li><code>ID</code>: an int64 node identifier</li><li><code>year</code>: the publication date of the paper (you can ignore this as it will not be used in our example but this property is part of the dataset)</li><li><code>x</code>: 128-dimensional node features (so 128-size float tensors)</li><li><code>y</code>: a numeric label indicating the category/field of the paper. These numbers indicate different <a href="https://arxiv.org/category_taxonomy" target="_blank" rel="noopener noreferrer">arXiv categories</a> for
papers. Although the exact mapping is not important, you can think of these for example as 0 indicating &quot;physics&quot;, 2 indicating &quot;geometry&quot; etc.</li></ul><p><em>Edges/Relationships</em> are citations between papers and do not contain any properties.</p><p><strong>Predictive task:</strong> Predict the <code>y</code> labels of nodes using the node features stored in the <code>x</code> properties.</p><p><strong>GNN Model</strong>: We will train a 3-layer GraphSage model that contains 5.6 million parameters to perform this predictive task. Our model is based on the implementation <a href="https://github.com/mengyangniu/ogbn-papers100m-sage/tree/main" target="_blank" rel="noopener noreferrer">here</a>. We picked this model because it was one of the better-performing models in the <a href="https://ogb.stanford.edu/docs/leader_nodeprop/" target="_blank" rel="noopener noreferrer">PyG Leaderboard for the ogbn-papers100M dataset</a> (search &quot;GraphSAGE_res_incep&quot; under &quot;Leaderboard for ogbn-papers100M&quot;) that we could develop using pre-existing layers in the PyG library (so we do not have to write any custom layers).</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-preliminaries-and-loading-ogbn-papers100m-into-kÃ¹zu">Step 1: Preliminaries and Loading ogbn-papers100M into KÃ¹zu<a href="#step-1-preliminaries-and-loading-ogbn-papers100m-into-kÃ¹zu" class="hash-link" aria-label="Direct link to Step 1: Preliminaries and Loading ogbn-papers100M into KÃ¹zu" title="Direct link to Step 1: Preliminaries and Loading ogbn-papers100M into KÃ¹zu">â€‹</a></h2><p>As a preliminary, the <a href="https://github.com/pyg-team/pytorch_geometric/blob/master/examples/kuzu/papers_100M/prepare_data.py" target="_blank" rel="noopener noreferrer"><code>prepare_data.py</code></a> script in <a href="https://github.com/pyg-team/pytorch_geometric/tree/master/examples/kuzu/papers_100M" target="_blank" rel="noopener noreferrer">Sample Code</a> generates four numpy files for each property of the papers: (i) <code>./ids.npy</code>; (ii) <code>./node_feat.npy</code> (storing <code>x</code> properties); (iii) <code>./node_year.npy</code>; and (iv) <code>./node_label.npy</code> (storing <code>y</code> labels). In addition, it will generate an <code>./edge_index.csv</code> file that stores the citation relationships. In the below code snippets, we will assume you have gone through those steps.</p><p>Let&#x27;s start with how you load the <code>ogbn-papers100M</code> dataset into KÃ¹zu. You will first need to define a <code>paper</code> NODE TABLE and a <code>cite</code> REL TABLE, whose schemas will follow exactly the structure of the dataset and then use <code>COPY FROM</code> statements in KÃ¹zu&#x27;s version of Cypher to ingest those numpy and csv files into your <code>paper</code> and <code>cite</code> tables:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import kuzu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Creating an empty KÃ¹zu database under the papers100M directory...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">db = kuzu.Database(&#x27;papers100M&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conn = kuzu.Connection(db, num_threads=cpu_count())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Creating KÃ¹zu tables...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conn.execute(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;CREATE NODE TABLE paper(id INT64, x FLOAT[128], year INT64, y FLOAT, &quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;PRIMARY KEY (id));&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conn.execute(&quot;CREATE REL TABLE cites (FROM paper TO paper, MANY_MANY);&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Copying nodes to KÃ¹zu tables...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conn.execute(&#x27;COPY paper FROM (&quot;%s&quot;,  &quot;%s&quot;,  &quot;%s&quot;, &quot;%s&quot;) BY COLUMN;&#x27; %</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             (&#x27;./ids.npy&#x27;, &#x27;./node_feat.npy&#x27;, &#x27;./node_year.npy&#x27;, &#x27;./node_label.npy&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Copying edges to KÃ¹zu tables...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conn.execute(&#x27;COPY cites FROM &quot;%s&quot;;&#x27; % (&#x27;./edge_index.csv&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;All done!&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The one important note here is that you should store your node features using <a href="https://kuzudb.com/docs/cypher/data-types/list.html" target="_blank" rel="noopener noreferrer">KÃ¹zu&#x27;s FIXED-LIST data type</a> using <code>FLOAT[128]</code> syntax (instead of the less efficient VAR-LIST data type, which uses <code>FLOAT[]</code> syntax for lists that can have different lengths). FIXED-LIST is a data type that we specifically added to KÃ¹zu to efficiently store node features and embeddings in graph ML applications.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-get-kÃ¹zu-remote-backend-by-calling-dbget_torch_geometric_remote_backend">Step 2: Get KÃ¹zu Remote Backend by Calling <code>db.get_torch_geometric_remote_backend()</code><a href="#step-2-get-kÃ¹zu-remote-backend-by-calling-dbget_torch_geometric_remote_backend" class="hash-link" aria-label="Direct link to step-2-get-kÃ¹zu-remote-backend-by-calling-dbget_torch_geometric_remote_backend" title="Direct link to step-2-get-kÃ¹zu-remote-backend-by-calling-dbget_torch_geometric_remote_backend">â€‹</a></h2><p>After loading your data to KÃ¹zu, the only thing you have to do is to call the <code>get_torch_geometric_remote_backend()</code> function on your Database object <code>db</code>:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">feature_store, graph_store = db.get_torch_geometric_remote_backend(multiprocessing.cpu_count())</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This function returns two objects that implement PyG&#x27;s Remote Backend interfaces: (i) <code>feature_store</code> is an instance of <a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.FeatureStore.html#torch_geometric.data.FeatureStore" target="_blank" rel="noopener noreferrer"><code>torch_geometric.data.FeatureStore</code></a>; and (ii) <code>graph_store</code> is an instance of <a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.GraphStore.html#torch_geometric.data.GraphStore" target="_blank" rel="noopener noreferrer"><code>torch_geometric.data.GraphStore</code></a>. These two handles are your KÃ¹zu Remote Backends that you can pass to your PyG models/subgraph samplers and they will make your existing PyG models work seamllessly with KÃ¹zu! That&#x27;s all
you really have to know about how to use KÃ¹zu as a Remote Backend. <strong><em>There is no more KÃ¹zu functions you have to call in the rest of the demonstration. You only have
to do 1 line of code change in your regular PyG code.</em></strong>
The rest of the example contains standard code you normally write to develop your PyG models.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-define--pass-kÃ¹zus-feature_store-and-graph_store-to-your-gnn-model">Step 3: Define &amp; Pass KÃ¹zu&#x27;s <code>feature_store</code> and <code>graph_store</code> to your GNN Model<a href="#step-3-define--pass-kÃ¹zus-feature_store-and-graph_store-to-your-gnn-model" class="hash-link" aria-label="Direct link to step-3-define--pass-kÃ¹zus-feature_store-and-graph_store-to-your-gnn-model" title="Direct link to step-3-define--pass-kÃ¹zus-feature_store-and-graph_store-to-your-gnn-model">â€‹</a></h2><p>First, we&#x27;ll define the GraphSage model in PyG. We&#x27;ll put <code>...</code>&#x27;s here and there to shorten the example because, as we said above, this is your regular PyG code:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Define the model for training. The model is ported from</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># https://github.com/mengyangniu/ogbn-papers100m-sage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class SAGE(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_feats, n_hidden, n_classes, n_layers, activation,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                 dropout):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.n_layers = n_layers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, edge_list, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for layer_index, layer in enumerate(self.layers):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ....</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.mlp(collect)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next, we will enable PyG to use KÃ¹zu&#x27;s Remote Backend when training. We create a <a href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/loader/neighbor_loader.html" target="_blank" rel="noopener noreferrer"><code>torch_geometric.loader.NeighborLoader</code></a>, which is the subgraph sampler we will use, and pass the <code>feature_store</code> and <code>graph_store</code> we obtained from KÃ¹zu to it. <strong><em>This is the 1 line change you have to do!</em></strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Plug the graph store and feature store into the NeighborLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kuzu_sampler = NeighborLoader(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data=(feature_store, graph_store),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_neighbors={(&#x27;paper&#x27;, &#x27;cites&#x27;, &#x27;paper&#x27;): [12, 12, 12]},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    batch_size=LOADER_BATCH_SIZE,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_nodes=(&#x27;paper&#x27;, input_nodes),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_workers=4,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    filter_per_worker=False,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong><code>data=(feature_store, graph_store)</code></strong> is the important line. When you use this sampler in training to construct mini-batches, it will perform subgraph sampling and load the required node features from KÃ¹zu automatically and return a <a href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.HeteroData.html" target="_blank" rel="noopener noreferrer"><code>torch_geometric.data.HeteroData</code></a> object, which can be directly plugged into a GNN model. That training code looks like this (again abbreviated because this is all PyG code):</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">model = SAGE(128, 1024, 172, 3, torch.nn.functional.relu, 0.2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">criterion = torch.nn.CrossEntropyLoss()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for epoch in range(NUM_EPOCHS):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    i = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    start_time = time.time()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // **The below for loop line is where we ask the sampler to</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // sample a mini batch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for b in kuzu_sampler:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = b[&#x27;paper&#x27;][&#x27;x&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = b[&#x27;paper&#x27;][&#x27;y&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        edge_index = b[&#x27;paper&#x27;, &#x27;cites&#x27;, &#x27;paper&#x27;].edge_index</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model.train()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        optimizer.zero_grad()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = model(edge_index, x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss = criterion(out, y)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss.backward()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        optimizer.step()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        i += 1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><code>for b in kuzu_sampler:</code> is the exact line where the sampler will end up calling on KÃ¹zu to sample a subgraph and scan the features of the nodes in that subgraph. This all ends up using KÃ¹zu&#x27;s disk-based storage, allowing you to train GNNs on graphs that don&#x27;t fit on your RAM. One distinct advantage of KÃ¹zu is that, because it is an embeddable DBMS,
we can do the conversion of scanned node features from KÃ¹zu into PyG&#x27;s tensors as a zero-copy operation. We simply write the scanned node features into a buffer array allocated in Python without any additional data transfer between the systems.</p><p>Currently, only the <code>feature_store</code> scans data from KÃ¹zu&#x27;s disk-based storage. For <code>graph_store</code>, our current implementation stores the entire graph topology in COO format in memory. This does limit how much you can scale, but in many models trained on large graphs, features take up more space than the graph topology, so scaling node features out of memory should still allow you to scale to very lage graphs that won&#x27;t fit in your RAM.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="adjusting-kÃ¹zus-buffer-pool-size">Adjusting KÃ¹zu&#x27;s Buffer Pool Size<a href="#adjusting-kÃ¹zus-buffer-pool-size" class="hash-link" aria-label="Direct link to Adjusting KÃ¹zu&#x27;s Buffer Pool Size" title="Direct link to Adjusting KÃ¹zu&#x27;s Buffer Pool Size">â€‹</a></h3><p>As with most DBMSs, KÃ¹zu has a Buffer Manager that maintains a buffer pool to keep parts of the database in memory. When you use KÃ¹zu, you decide how much memory to allocate to it. The more memory you give to KÃ¹zu, the less I/O it will perform on scans. So, in the context of this post, the larger the buffer manager size you set, the faster your training time will be when training large graphs out of memory. You set KÃ¹zu&#x27;s buffer pool size when you construct your <code>Database</code> object, before you call the <code>get_torch_geometric_remote_backend()</code> function. For example, the code below sets the BM size to <code>40 * 1024**3</code> bytes, which is equal to 40GB. You should set it as high as possible without running out of memory for performance reasons.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">KUZU_BM_SIZE = 40 * 1024**3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create kuzu database</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">db = kuzu.Database(&quot;papers100M&quot;, KUZU_BM_SIZE)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">feature_store, graph_store = db.get_torch_geometric_remote_backend(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mp.cpu_count())</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="an-experiment-demonstrating-throughput-numbers-with-different-buffer-pool-sizes">An Experiment Demonstrating Throughput Numbers With Different Buffer Pool Sizes<a href="#an-experiment-demonstrating-throughput-numbers-with-different-buffer-pool-sizes" class="hash-link" aria-label="Direct link to An Experiment Demonstrating Throughput Numbers With Different Buffer Pool Sizes" title="Direct link to An Experiment Demonstrating Throughput Numbers With Different Buffer Pool Sizes">â€‹</a></h2><p>Let&#x27;s demonstrate what troughput numbers you can expect under different memory settings.
As a baseline we will first measure the throughput of training
as time/batch using PyG&#x27;s default in-memory
storage. This seting uses ~106GB of memory.
We will then simulate limited memory settings by training the same
model using KÃ¹zu Remote Backend and limiting KÃ¹zu&#x27;s buffer pool size to
different levels.
Here are the important configurations for the experiment:</p><ul><li>Available RAM in the machine: 384GB RAM</li><li>CPU: Two Xeon Platinum 8175M (48 cores/96 threads)</li><li>GPU: RTX 4090 with 24GB GPU memory</li><li>SSD in the system for disk storage: 2TB Kingston KC3000 NVMe SSD</li><li>Mini-batch size: 1152. Recall the <code>kuzu_sampler = NeighborLoader(...)</code> that we defined above. There we gave this argument
<code>num_neighbors={(&#x27;paper&#x27;, &#x27;cites&#x27;, &#x27;paper&#x27;): [12, 12, 12]}</code> to the <code>NeighborLoader</code>, which means that the sampler will sample 3-degree neighbors of these 1152 nodes,
sampling 12 neighbors at each degree.
We picked 1152 as our mini-batch size because this is the size at which we generate batches that take a peak of 23GB of memory, so beyond this we would run out of GPU memory. <sup id="fnref-1-5f0073"><a href="#fn-1-5f0073" class="footnote-ref">1</a></sup></li><li>#<!-- --> PyG Workers: 16 (we did a parameter sweep and setting this to 4, 8, 16 perform very similarly)</li><li>#<!-- --> KÃ¹zu Query Processor Threads: 24 (48 and 96 also perform similarly)</li></ul><p>We will run KÃ¹zu with 60GB, 40GB, 20GB, and 10GB buffer pool size.
The lower KÃ¹zu&#x27;s buffer pool size, the more
disk I/Os KÃ¹zu will perform. Note however that in this experiment KÃ¹zu will use more memory than
these sizes for two reasons: (i) KÃ¹zu stores some parts of the database always in memory
though this is not very important in this setting; (ii) As we said, currently
KÃ¹zu Remote Backend uses in-memory storage for the graph topology (but not node features!),
which takes ~48GB of RAM. So you can roughly think of KÃ¹zu using 48 + BM size in these experiments.</p><p>We will do 500 batches of training and report the throughput number as average end-to-end time/batch.
We also report the time that&#x27;s spent on GPU for Training as <code>Training Time (s)</code> and
time spent on copying data from CPU to GPU as <code>CPU-to-GPU Copying Time (s)</code>. For
KÃ¹zu configurations, you can roughly
interpret <code>Per Batch Time (s) -  Training Time (s) -  CPU-to-GPU Copying Time (s)</code>
as the time spent for scanning data from KÃ¹zu into CPU&#x27;s memory. We expect that to increase
as we lower the BM size.</p><table><thead><tr><th>Configuration</th><th>Per Batch Time (s)</th><th>Training Time (s)</th><th>CPU-to-GPU Copying Time</th><th>Time Scanning Data from KÃ¹zu</th><th>Memory Usage</th></tr></thead><tbody><tr><td>PyG In-memory</td><td>0.281</td><td>0.240</td><td>0.024</td><td>---</td><td>~110 GB</td></tr><tr><td>KÃ¹zu Remote Backend (bm=60GB)</td><td>0.380 (1.35x)</td><td>0.239</td><td>0.018</td><td>0.123</td><td>~110 GB</td></tr><tr><td>KÃ¹zu Remote Backend (bm=40GB)</td><td>0.513 (1.82x)</td><td>0.239</td><td>0.022</td><td>0.251</td><td>~90 GB</td></tr><tr><td>KÃ¹zu Remote Backend (bm=20GB)</td><td>1.162 (4.88x)</td><td>0.238</td><td>0.022</td><td>0.901</td><td>~70 GB</td></tr><tr><td>KÃ¹zu Remote Backend (bm=10GB)</td><td>1.190 (4.23x)</td><td>0.238</td><td>0.022</td><td>0.930</td><td>~60 GB</td></tr></tbody></table><p>So, when have enough memory, there is about 1.35x slow down (from 0.281s to 0.380s per batch)
compared to using PyG&#x27;s default storage. This
is the case when KÃ¹zu has enough buffer memory (60GB) to store the features but we still incur the cost of
scanning them through KÃ¹zu&#x27;s buffer manager. So no disk I/O happens (except the first time
the features are scanned to the buffer manager). When we use 40GB of buffer pool and below, we start doing some I/O,
and the average time per batch degrade to 0.513, 1.162, amd 1.190 respectively when using 40GB, 20GB, and 10GB.
We seem to stabilize around 4x degradation at 10GB or 20GB level, where most of the feature scans
are now happening from disk. These numbers hopefully look good for many settings!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps">â€‹</a></h2><p>We will be doing 2 immediate optimizations in the next few releases
related to KÃ¹zu&#x27;s PyG integration.
First, we will change our <code>graph_store</code> to use an in DBMS subgraph sampler, so we can virtually work at any limited memory level.
Second, in an even earlier release, we had a more basic PyG integration feature, the
<a href="https://kuzudb.com/docs/client-apis/python-api/query-result.html#query_result.QueryResult.get_as_torch_geometric" target="_blank" rel="noopener noreferrer"><code>QueryResult.get_as_torch_geometric()</code></a> function.
This feature is more of an ETL feature. It is designed for cases where you want to filter
a subset of your nodes and edges and convert them directly into PyG <code>HeteroData</code> objects (i.e., use PyG&#x27;s default in-memory storage)
as you build PyG pipelines using graph databases you store in KÃ¹zu.
If you are converting a large graph this can be quite slow, and we will be improving this so that such ETL pipelines
are much faster!</p><p>We are excited to hear about your feedback on KÃ¹zu&#x27;s PyG integration features and get more ideas about
how else we can help users who are building GNN pipelines. Please reach out to us over <a href="https://join.slack.com/t/kuzudb/shared_invite/zt-1w0thj6s7-0bLaU8Sb~4fDMKJ~oejG_g" target="_blank" rel="noopener noreferrer">KÃ¹zu Slack</a>
for your questions and ideas!.</p><div class="footnotes"><hr><ol><li id="fn-1-5f0073">If you read our <a href="https://kuzudb.com/blog/kuzu-0.0.3-release.html#k%C3%B9zu-as-a-pyg-remote-backend" target="_blank" rel="noopener noreferrer">v0.0.3 blog post</a>,
which had a shorter section about PyG interface, you will notice that we used a much larger batch size there (48000),
which was the size that saturated GPU memory. Although the example there was also on the <code>ogbn-papers100M</code> dataset, we used a much smaller model with ~200K parameters
and sampled subgraphs from 2 degree neighbors of these batches. Now we use a much larger model with 5.6 million parameters and samples from 3-degree neighbors.<a href="#fnref-1-5f0073" class="footnote-backref">â†©</a></li></ol></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/use-case">use-case</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docusaurus/blog/kuzu-0.0.4-release"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">KÃ¹zu 0.0.4 Release</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docusaurus/blog/kuzu-0.0.3-release"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">KÃ¹zu 0.0.3 Release</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#dataset-predictive-task-and-gnn-model" class="table-of-contents__link toc-highlight">Dataset, Predictive Task, and GNN Model</a></li><li><a href="#step-1-preliminaries-and-loading-ogbn-papers100m-into-kÃ¹zu" class="table-of-contents__link toc-highlight">Step 1: Preliminaries and Loading ogbn-papers100M into KÃ¹zu</a></li><li><a href="#step-2-get-kÃ¹zu-remote-backend-by-calling-dbget_torch_geometric_remote_backend" class="table-of-contents__link toc-highlight">Step 2: Get KÃ¹zu Remote Backend by Calling <code>db.get_torch_geometric_remote_backend()</code></a></li><li><a href="#step-3-define--pass-kÃ¹zus-feature_store-and-graph_store-to-your-gnn-model" class="table-of-contents__link toc-highlight">Step 3: Define &amp; Pass KÃ¹zu&#39;s <code>feature_store</code> and <code>graph_store</code> to your GNN Model</a><ul><li><a href="#adjusting-kÃ¹zus-buffer-pool-size" class="table-of-contents__link toc-highlight">Adjusting KÃ¹zu&#39;s Buffer Pool Size</a></li></ul></li><li><a href="#an-experiment-demonstrating-throughput-numbers-with-different-buffer-pool-sizes" class="table-of-contents__link toc-highlight">An Experiment Demonstrating Throughput Numbers With Different Buffer Pool Sizes</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://join.slack.com/t/kuzudb/shared_invite/zt-1w0thj6s7-0bLaU8Sb~4fDMKJ~oejG_g" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/kuzudb" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@KuzuDB" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/410352593" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docusaurus/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/kuzudb/kuzu" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 KÃ¹zu Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/docusaurus/assets/js/runtime~main.044b3ffa.js"></script>
<script src="/docusaurus/assets/js/main.6b97b9f5.js"></script>
</body>
</html>