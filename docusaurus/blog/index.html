<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Blog | Kùzu</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" property="og:url" content="https://kuzudb.com/docusaurus/blog"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="og:locale" content="en_US"><meta data-rh="true" name="og:type" content="article"><meta data-rh="true" name="og:site_name" content="Kùzu"><meta data-rh="true" name="og:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="twitter:site" content="@kuzudb"><meta data-rh="true" name="twitter:creator" content="@kuzudb"><meta data-rh="true" name="twitter:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" property="og:title" content="Blog | Kùzu"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/docusaurus/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://kuzudb.com/docusaurus/blog"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog" hreflang="en"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XV0PE3XW33-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/docusaurus/blog/rss.xml" title="Kùzu RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/docusaurus/blog/atom.xml" title="Kùzu Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Kùzu" href="/docusaurus/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer"><link rel="stylesheet" href="/docusaurus/assets/css/styles.6fd37a31.css">
<link rel="preload" href="/docusaurus/assets/js/runtime~main.990e818c.js" as="script">
<link rel="preload" href="/docusaurus/assets/js/main.486ad7a4.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://kuzudb.com/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/docusaurus/img/kuzu-logo.png" alt="Kùzu" class="themedImage_ToTc themedImage--light_HNdA"><img src="/docusaurus/img/kuzu-logo-inverse.png" alt="Kùzu" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/docusaurus/installation">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docusaurus/blog/">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item">
            <a href="https://github.com/kuzudb/kuzu" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-github fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://discord.gg/jw7xN2ZhJB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-discord fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://twitter.com/kuzudb" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-twitter fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://www.youtube.com/@KuzuDB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-youtube fa-xl"></i>
            </a>
            </div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/transforming-your-data-to-graphs-1">Transforming your data to graphs - Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-2">RAG Using Unstructured Data &amp; Role of Knowledge Graphs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-1">RAG Using Structured Data: Overview &amp; Important Questions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.1.0-release">Kùzu 0.1.0 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.12-release">Kùzu 0.0.12 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzuexplorer">KùzuExplorer: Visualizing Query Results and Schemas</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.11-release">Kùzu 0.0.11 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.10-release">Kùzu 0.0.10 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.9-release">Kùzu 0.0.9 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.8-release">Kùzu 0.0.8 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.7-release">Kùzu 0.0.7 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/iamgraphviz">IAMGraphViz: Visualizing AWS IAM Permissions with Kùzu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.6-release">Kùzu 0.0.6 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.5-release">Kùzu 0.0.5 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.4-release">Kùzu 0.0.4 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-pyg-remote-backend">Scaling Pytorch Geometric GNNs With Kùzu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.3-release">Kùzu 0.0.3 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/wcoj">Why (Graph) DBMSs Need New Join Algorithms: The Story of Worst-case Optimal Join Algorithms</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.2-release">Kùzu 0.0.2 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/factorization">Factorization &amp; Great Ideas from Database Theory</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/what-every-gdbms-should-do-and-vision">What Every Competent GDBMS Should Do (aka The Goals &amp; Vision of Kùzu)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/meet-kuzu">Meet Kùzu 🤗</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/transforming-your-data-to-graphs-1">Transforming your data to graphs - Part 1</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-24T00:00:00.000Z" itemprop="datePublished">January 24, 2024</time> · <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/prrao87" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/prashanth.png" alt="Prashanth Rao"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/prrao87" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Prashanth Rao</span></a></div><small class="avatar__subtitle" itemprop="description">AI Engineer at Kùzu Inc.</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Ever since the birth of database management systems (DBMSs), tabular relations and graphs have been
the core data structures used to model application data in two broad classes of systems:
relational DBMSs (RDBMS) and graph DBMSs (GDBMS).</p><p>In this post, we&#x27;ll look at how to transform data that might exist in a typical relational system
to a graph and load it into a Kùzu database. The aim of this post and the next one is to showcase
&quot;graph thinking&quot;<sup id="fnref-1-105625"><a href="#fn-1-105625" class="footnote-ref">1</a></sup>, where you explore connections in your existing structured data and apply
it to potentially uncover new insights.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Code</div><div class="admonitionContent_S0QG"><p>The code to reproduce the workflow shown in this post can be found in the
<a href="https://github.com/kuzudb/graphdb-demo/tree/main/src/python/transactions" target="_blank" rel="noopener noreferrer">graphdb-demo</a> repository.
It uses Kùzu&#x27;s Python API, but you are welcome to use the client API <a href="https://kuzudb.com/docusaurus/client-apis" target="_blank" rel="noopener noreferrer">of your choice</a>.</p></div></div></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/use-case">use-case</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Transforming your data to graphs - Part 1" href="/docusaurus/blog/transforming-your-data-to-graphs-1"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/llms-graphs-part-2">RAG Using Unstructured Data &amp; Role of Knowledge Graphs</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-15T00:00:00.000Z" itemprop="datePublished">January 15, 2024</time> · <!-- -->20 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/team.jpg" alt="Semih Salihoğlu"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Semih Salihoğlu</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of Kùzu Inc. &amp; Associate Prof. at UWaterloo</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://kuzudb.com/docusaurus/blog/llms-graphs-part-1" target="_blank" rel="noopener noreferrer">In my previous post</a>,
I gave an overview of question answering (Q&amp;A) systems that use LLMs
over private enterprise data. I covered the architectures of these systems, the common tools
developers use to build these systems when the enterprise data used is structured,
i.e., data exists as records stored in some DBMS, relational or graph. I was referring to
these systems as <em>RAG systems using structured data</em>. In this post, I cover <em>RAG systems
that use unstructured data</em>, such as text files,
pdf documents, or internal html pages in an enterprise. I will refer to these as RAG-U systems
or sometimes simply as RAG-U (should have used the term RAG-S in the previous post!).</p><p>To remind readers, I decided to
write these two posts after doing a lot of reading in the space to understand the role of
knowledge graph (KGs) and graph DBMSs in LLM applications. My goals are (i) to overview the field to readers who want to get started
but are intimidated by the area; and (ii) point to several future work directions that I find
important.<sup id="fnref-1-c9223b"><a href="#fn-1-c9223b" class="footnote-ref">1</a></sup></p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>TL;DR: The key takeaways from this post are:</div><div class="admonitionContent_S0QG"><ul><li><strong>Two design decisions when preparing a RAG-U system are (i) &quot;What additional data&quot; to put in prompts; and (ii) &quot;How to store and fetch&quot; the additional data.</strong>: Explored options for types of additional data include chunks of texts, full documents, or automatically extracted triples from documents. There are different ways to store and fetch this additional data, such as use of vector indices. Many combinations of this design space are not yet explored.</li><li><strong>Standard RAG-U</strong>: A common design point, which I will call the standard RAG-U, is to add chunks of documents as additional data and store them in a vector index. I found some of the most technically deep and interesting future work directions in this space, e.g., extending vectors to matrices.</li><li><strong>An envisioned role for KGs in a RAG-U system is as a means to link chunks of text:</strong> If chunks can be linked to entities in an existing KG, then one can connect chunks to each other through the relationships in KG.
These connections can be exploited to retrieve more relevant chunks. This is a promising direction but
its potential benefits should be subjected to rigorously evaluation, e.g., as major SIGIR publications evaluate a new retrieval technique. It won&#x27;t pick up through commercial blog posts.</li><li><strong>What if an enterprise does not have a KG?</strong> The hope of using KGs to do better retrieval in absence of a pre-existing KG raises the question and never ending quest of <em>automatic knowledge graph construction</em>. This is a very interesting topic and most recent research here uses LLMs for this purpose but: (i) LLMs seem behind in extracting quality knowledge graph facts; and (ii) it&#x27;s not clear if use of LLMs for this purpose at scale is economically feasible.</li></ul></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag-u-overview">RAG-U Overview<a href="#rag-u-overview" class="hash-link" aria-label="Direct link to RAG-U Overview" title="Direct link to RAG-U Overview">​</a></h2><p>I will skip the overview of RAG systems, which I covered in <a href="https://kuzudb.com/docusaurus/blog/llms-graphs-part-1#a-note-on-the-term-rag" target="_blank" rel="noopener noreferrer">the previous post</a>.
The picture of RAG systems that use unstructured data looks as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/rag-unstructured-overview-9cf06430dbd5bc1a010aa69dd7b98f6a.png" width="600" class="img_ev3q"></div><p>An enterprise has a corpus of unstructured data, i.e., some documents with text.
As a preprocessing step (omitted from the figure), the information in these documents are indexed and
stored in some storage system. The figure labels the 4 overall steps in a RAG-U system:</p><ol><li>A natural language query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> comes into the RAG-U system.</li><li>Parts of the corpus of unstructured data that is expected to be helpful in answering <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
is fetched from some storage system.</li><li>The fetched data along with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> given to an LLM.</li><li>LLM produces a natural language answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> for <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.</li></ol><p>Any system built along these 4 high-level steps needs to make two design choices:</p><p><strong>Design Choice 1: What is the additional data?</strong> Among the posts, documentation, and demonstrations
I have read, I have seen three designs:</p><ul><li>Chunks of documents</li><li>Entire documents</li><li>Triples extracted from documents</li></ul><p><strong>Design Choice 2: How to store and fetch the additional data?</strong> Here, I have seen the following designs:</p><ul><li>Vector Index</li><li>Vector Index + Knowledge Graph (stored in a GDBMS)</li><li>GDBMS (for storing triples)</li></ul><p>Many combinations of these two choices are possible and can be tried. Each choice
can effectively be understood as a <em>retrieval heuristic</em> to fetch quality content that can
help LLMs answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> more accurately.
I will cover a few of the ones that I have seen but others are certainly possible and should be tried by people
developing RAG-U systems.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="standard-rag-u-chunks-of-documents-stored-in-a-vector-index">Standard RAG-U: Chunks of Documents Stored in a Vector Index<a href="#standard-rag-u-chunks-of-documents-stored-in-a-vector-index" class="hash-link" aria-label="Direct link to Standard RAG-U: Chunks of Documents Stored in a Vector Index" title="Direct link to Standard RAG-U: Chunks of Documents Stored in a Vector Index">​</a></h2><p>Standard RAG-U is what you will read about in most places. Its design is as follows: (i) we split the text in the
documents into (possibly overlapping) &quot;chunks&quot;; (ii) we embed these chunks into vectors, i.e., high dimensional points, using
a text embedding model (many off-the-shelf open-source models exist from <a href="https://platform.openai.com/docs/guides/embeddings" target="_blank" rel="noopener noreferrer">OpenAI</a>, <a href="https://docs.cohere.com/reference/embed" target="_blank" rel="noopener noreferrer">Cohere</a>, and <a href="https://huggingface.co/blog/getting-started-with-embeddings" target="_blank" rel="noopener noreferrer">Hugging Face</a>);
and (iii) we store these vectors in a vector index. For example, see LangChain main documentation
on &quot;<a href="https://python.langchain.com/docs/use_cases/question_answering/" target="_blank" rel="noopener noreferrer">Q&amp;A with RAG</a>&quot; or LlamaIndex&#x27;s
&quot;<a href="https://docs.llamaindex.ai/en/stable/examples/low_level/oss_ingestion_retrieval.html" target="_blank" rel="noopener noreferrer">Building a RAG from Scratch</a>&quot; documentation.
The below figure shows the pre-processing and indexing steps of standard RAG-U:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/standard-rag-preprocessing-2ed0ed6a8e1e4583cc0036aa0e7a95f1.png" width="600" class="img_ev3q"></div><p><strong>First a note on vector indices:</strong> A vector index is one that indexes a
set of d-dimensional vectors and given a query vector w can answer several queries:
(i) <em>pure search</em>: does w exist in the index?; (ii) <em>k nearest neighbors</em>: return
the k vectors closest to w; or (iii) <em>range queries</em>: return vectors that are within
a radius r of w. There have been decades of work on this topic.
If d is very small, say 3 or 4, there are &quot;exact spatial indices&quot; like <a href="https://en.wikipedia.org/wiki/Quadtree" target="_blank" rel="noopener noreferrer">quad trees</a> (for 2D only), <a href="https://en.wikipedia.org/wiki/R-tree" target="_blank" rel="noopener noreferrer">r-trees</a>, or <a href="https://en.wikipedia.org/wiki/K-d_tree" target="_blank" rel="noopener noreferrer">k-d trees</a>.
These indices have good construction and query times when d is small but their performance degrades
fast when d increases and they quickly become impractical.
There have been some good work to index high-dimensional vectors as well.
<a href="https://dl.acm.org/doi/10.1007/s007780200060" target="_blank" rel="noopener noreferrer">SA-trees</a> by Navarro is the core
technique that underlies the nowadays popular indices, such as <a href="https://arxiv.org/abs/1603.09320" target="_blank" rel="noopener noreferrer">hierarchical navigable small-world graph (HNSW) indices</a>, which are extensions of <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306437913001300" target="_blank" rel="noopener noreferrer">navigable small world (NSW)
indices</a>.
Navarro&#x27;s SA-tree index returns exact results as well<sup id="fnref-2-c9223b"><a href="#fn-2-c9223b" class="footnote-ref">2</a></sup> but does not have good query times.
In Navarro&#x27;s experiments, even for
relatively small dimensions such as 10-20, sa-tree can scan 10-100% of all vectors in the index
for queries that need to return less than 1% of the vectors.
SNW and HSNW instead are not exact indices. They are called approximate indices but they are not
even approximate in the sense of having any approximation guarantees in their query results.
They are heuristic-based indices that can index very high-dimensional vector and are fast
both in their construction and their query times. Further, their query results are shown to be quite accurate empirically.
HNSW indices are nowadays used by vector databases like <a href="https://www.pinecone.io/learn/series/faiss/hnsw/" target="_blank" rel="noopener noreferrer">Pinecone</a>
and <a href="https://weaviate.io/developers/weaviate/concepts/vector-index" target="_blank" rel="noopener noreferrer">Weaviate</a> or search engine libraries such as <a href="https://lucene.apache.org/core/9_1_0/core/org/apache/lucene/util/hnsw/HnswGraph.html" target="_blank" rel="noopener noreferrer">Lucene</a> in their vector indices.
To understand these indices, I highly suggest first reading the Navarro paper
paper, which is the foundation. It&#x27;s also a great example of a well-written database paper: one that
makes a very clear contribution and is explained in a very clean technical language.</p><p>Back to RAG-U. After the preprocessing step, the vector index that contains the chunks of documents is used
in a RAG-U system as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/standard-rag-overview-1a978709d941cd0aa9c64f7135ee6b2c.png" width="600" class="img_ev3q"></div><p>The step are as follows: (i) The question <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> is first embedded into
the same d-dimensional vector space as the chunks were. Let&#x27;s call this vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>;
(ii) k nearest neighbors <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> are searched in the vector index (for some value of k) ; and (iii) the chunks
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> that correspond to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> are retrieved (in the figure above, these
are the chunks in red boxes) and put into the LLM prompt along with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. The
hope is that the chunks whose vector representation were close to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> contain
useful information for the LLM to answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. In practice there could be more steps to rank those <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> chunks
and maybe select a fewer number of them to give to the LLM.</p><p>Overall, my reading on standard RAG-U was quite technically deep. That&#x27;s not surprising since
the success of these pipelines depend on two core technical problems:</p><ol><li>How &quot;good&quot; are the embeddings that are inserted into the vector index, i.e., how well does it
capture the relatedness of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to the chunks. This is a core problem in the neural IR.</li><li>How accurate is the vector index in finding top-k nearest neighbors to the vector embedding <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
This is a core database problem.</li></ol><p><em>Important Future Work 1</em>: I believe we should be seeing more exciting work coming up in this space. One
topic is the use of matrices instead of vectors to embed chunks and questions.
This is done in the <a href="https://huggingface.co/colbert-ir/colbertv2.0" target="_blank" rel="noopener noreferrer">ColBERT-style</a> &quot;neural retrieval models&quot;
that are shown to work well on some Q&amp;A benchmarks. Indexing and retrieval of these matrices is an interesting
topic and I have even seen some off-the-shelf tools, e.g., the <a href="https://llamahub.ai/l/llama_packs-ragatouille_retriever?from=llama_packs" target="_blank" rel="noopener noreferrer">RAGatouille package of LlamaIndex</a>, that allows developers to replace the vectors in the
standard RAG-U figure above with matrices. Tons of good future work is possible in this space from improving the accuracy
and efficiency of the vector/matrix indices to the evaluation of RAG-U systems that use these vectors.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="first-envisioned-role-of-knowledge-graphs-in-rag-u-explicitly-linking-chunks">First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks<a href="#first-envisioned-role-of-knowledge-graphs-in-rag-u-explicitly-linking-chunks" class="hash-link" aria-label="Direct link to First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks" title="Direct link to First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks">​</a></h2><p>One limitation of standard RAG-U is that the chunks are treated as isolated pieces of text. To address this problem,
several posts
that I read (<a href="https://medium.com/neo4j/implementing-advanced-retrieval-rag-strategies-with-neo4j-c968a002c513" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://medium.com/neo4j/using-a-knowledge-graph-to-implement-a-devops-rag-application-b6ba24831b16" target="_blank" rel="noopener noreferrer">2</a>) envision linking these chunks to each other using a KG (or another form of graph). Compared to standard RAG-U,
the design choice for &quot;what additional data&quot; is still document chunks but &quot;how to fetch&quot; is different
and it is a mix of vector index + a KG stored in a GDBMS.
The preprocessing over standard RAG-U (see the preprocessing figure above)
would be enhanced with an additional step as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/kg-enhanced-rag-preprocessing-0258a645794605b4b9469f2756c4a562.png" width="600" class="img_ev3q"></div><p>That is, using some entity extraction mechanism, the chunks would be linked to the entities that
they mention in the KG (assuming the KG contains these entities as nodes). You can think of this linking
as the adding new edges to the KG that relate entities to some chunkIDs that identify the chunks in the vector index.
After the preprocessing step, the standard RAG-U system would be enhanced as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/kg-enhanced-rag-overview-57a9ca61a3e3739118a711237fa28740.png" width="600" class="img_ev3q"></div><p>Similar to standard RAG-U, we have a vector index and additionally a KG, say stored in a GDBMS.
As before <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> is embedded into a vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>, whose k nearest neighbors
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> and their corresponding chunks <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
are found in the vector index.
Then, the system extracts additional chunks based on some graph
traversal heuristic. A simple heuristic is to traverse from the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to all entities,
say {<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">e_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>}, that are mentioned in <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
Then, we can optionally explore the neighborhood of these entities
to extract other entities, say {<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">e_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">e_{m+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">e_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>}, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">e_{m+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span> to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">e_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
are the new entities extracted. Then, we further find other chunks that mention these entities. In the figure
above I&#x27;m simulating this by having a third red box that was not retrieved in the standard RAG-U figure. Now through
another ranking, we can obtain another top-k chunks amongst this new set of chunks and put them into the prompt.</p><p>This vision is interesting and several prior papers also hint at similar related use of
KGs in Q&amp;A applications. The most interesting paper I read that&#x27;s related to this approach was this <a href="https://aclanthology.org/P19-1598.pdf" target="_blank" rel="noopener noreferrer">ACL 2019 paper</a>. This paper pre-dates the current LLMs and is not about RAG. Instead, it
maps the entities mentioned in a question to entities in a KG, and then extracts the subgraph of relations between these
entities from the KG. Then, the relations and entities in this subgraph are used as possible
answers to the question (in some sense, this is also a form of RAG).
The paper&#x27;s approach does not connect the chunks but connects the entities in the question using a KG.
Overall, I think the idea of linking chunks through the entities that they mention is promising
and I want to identify three important future work here that can push this approach forward.</p><p><strong>Important Future Work 2:</strong> This approach assumes that the enterprise already
has a knowledge graph. Although I am a strong believer that enterprises
should invest in the construction of clean enterprise-level KGs with
well defined and consistent vocabularies,
in practice many enterprises do not have readily-available KGs. Therefore the use of this style
of KG-enhanced RAG-U approaches rely on tools that can generate KGs. This is a never ending
quest in academic circles and I&#x27;ll say more about this below (see &quot;Important Future Work 5&quot;).</p><p><em>Important Future Work 3:</em> The graph heuristic I described above to extract further chunks
is only one that can be explored amongst many others. For example, one can map the entities in the question
to nodes in the KG, find shortest paths between them, and retrieve the chunks that mention the nodes/entities
on these paths. These variants need to be systematically evaluated to optimize this approach.</p><p><em>Important Future Work 4:</em> Although variants of this approach, such as  the ACL paper I mentioned have a lot of technical depth
and rigorous evaluations, this approach so far appears only in blog posts which don&#x27;t present an in-depth study. This approach
needs to be subjected to a rigorous evaluation on Q&amp;A benchmarks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-envisioned-role-of-knowledge-graphs-in-rag-u-extracting-triples-out-of-chunks">Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks<a href="#second-envisioned-role-of-knowledge-graphs-in-rag-u-extracting-triples-out-of-chunks" class="hash-link" aria-label="Direct link to Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks" title="Direct link to Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks">​</a></h2><p>In the <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html" target="_blank" rel="noopener noreferrer">LlamaIndex KnowledgeGraphIndex</a> package, there is one more usage of KGs in RAG-U applications.
In this approach, the answer to the &quot;what additional data&quot; question is &quot;triples extracted from the unstructured documents&quot;.
The answer to the &quot;how to fetch&quot; question is to do a retrieval of these triples from a GDBMS.
Here is the preprocessing step:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/triples-based-rag-preprocessing-a78585b0799b8bc8ffb947f170bff914.png" width="600" class="img_ev3q"></div><p>Using some triple extraction, the unstructured document is pre-processed to generate a KG. I will discuss
this step further but overall you can use either a triple extraction model, such as <a href="https://huggingface.co/Babelscape/rebel-large" target="_blank" rel="noopener noreferrer">REBEL</a> or another model, or an LLM directly. Both can be used off-the-shelf. Then, these triples, which form
a KG, are stored in a GDBMS and used in RAG in some form. I&#x27;m giving one example approach below but others
are possible. The approach I will show
is implemented in the examples used in LlamaIndex&#x27;s documentations using <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html" target="_blank" rel="noopener noreferrer">LlamaIndex KnowledgeGraphIndex</a>:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/triples-based-rag-overview-8034260dd33e3c205ab472f2f292eb2b.png" width="600" class="img_ev3q"></div><p>The triples are stored in a GDBMS. You can use a <a href="https://docs.llamaindex.ai/en/stable/community/integrations/graph_stores.html" target="_blank" rel="noopener noreferrer">LlamaIndex GraphStore</a> for this and Kùzu has an implementation; see the <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KuzuGraphDemo.html" target="_blank" rel="noopener noreferrer">KuzuGraphStore demo here</a>. The system extract entities using <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, using some
entity or keyword extractor. In the LlamaIndex demos, this is done by using an LLM. Specifically,
LLM is prompted with the following <a href="https://github.com/run-llama/llama_index/blob/ce82bd42329b56bca2a6a44e0f690ebedaf1f002/llama_index/prompts/default_prompts.py#L147" target="_blank" rel="noopener noreferrer">prompt</a>: <code>A question is provided below. Given the question, extract up to {max_keywords}
keywords from the text....</code> etc. These keywords are used
to extract triples from the GDBMS by using them in the query sent to the GDBMS as shown in the above figure.
Finally the returned triples are given to the LLM prompt as additional data to help answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.</p><p>LlamaIndex offer other ways to extract these triples that are also readily available to use. For example,
you can embed these triples into vectors and use a vector index to fetch them. So although the final
additional data is still triples, how they&#x27;re fetched is through a vector index and not a GDBMS. Other options
are also possible.</p><p>I want to make three points here. First, notice that extracting triples also
provides a means to link the text in the unstructured text, which was a
shortcoming I had highlighted in standard RAG-U. Second, by putting triples into prompts instead of chunks, you are also probably
saving the tokens you are using in your LLM applications. That&#x27;s because triples are like summaries
of the statements in more verbose sentences in chunks.
Third, the success of such RAG applications depends on the quality of the triples
extracted in the pre-processing step, which is the next future work direction I want to highlight:</p><p><em>Important Future Work 5:</em> The success of RAG-U applications that use triples or the KG-enhanced standard
RAG-U applications depend on the availability of a technology that can automatically
extract knowledge graphs from unstructured documents.</p><p>This is a fascinating topic and is a never ending quest in research. Here is
an <a href="https://arxiv.org/pdf/2302.05019.pdf" target="_blank" rel="noopener noreferrer">extensive survey</a> with 358 citations that scared me so I decided to
skip it. But my point is that this has been a never ending research topic. The most recent
work I see here is on using LLMs for this task. I can recommend these two papers here: <a href="https://arxiv.org/abs/2208.11057" target="_blank" rel="noopener noreferrer">1</a> and <a href="https://arxiv.org/pdf/2308.10168.pdf" target="_blank" rel="noopener noreferrer">2</a>.
General conclusions so far are that LLMs are not yet competitive with specialized models
on extracting high quality triples. We&#x27;ll see how far they will go. Surprisingly, a very important question
for which I could not find much to read on is this:</p><p><em>Important Future Work 6:</em> How economical would be the use of LLMs to extract KGs at scale (when they&#x27;re competitive with
specialized methods)? </p><p>So could we ever dream of using LLMs to extract billions of triples from a large corpus of unstructured documents? Probably not
if you&#x27;re using OpenAI APIs, as it would be painfully expensive, or even if you&#x27;re running
your own model, as it would be excruciatingly slow. So I am a bit pessimistic here. My instinct
is that you might be able to generate KGs from unstructured documents using the slightly older
techniques like designing your own models or using extractor-based approaches like
<a href="http://deepdive.stanford.edu/" target="_blank" rel="noopener noreferrer">DeepDive</a><sup id="fnref-3-c9223b"><a href="#fn-3-c9223b" class="footnote-ref">3</a></sup> and <a href="https://tomaarsen.github.io/SpanMarkerNER/" target="_blank" rel="noopener noreferrer">SpanMarker</a><sup id="fnref-4-c9223b"><a href="#fn-4-c9223b" class="footnote-ref">4</a></sup>. I know it&#x27;s not exciting to not use LLMs,
but you&#x27;re likely to extract much higher quality triples and much more cheaply with specialized models.
So I don&#x27;t know who really
thinks it could one day be a good idea to use LLMs to extract triples from large corpuses.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="agents-developing-rag-systems-that-use-both-structured--unstructured-data">Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data<a href="#agents-developing-rag-systems-that-use-both-structured--unstructured-data" class="hash-link" aria-label="Direct link to Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data" title="Direct link to Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data">​</a></h2><p>Let me now start wrapping up. In my last post and this one, I covered RAG systems using structured and unstructured data.
There are several tools you can use to develop RAG systems that retrieve data from both
structured records or one that conditionally retrieves from one or the other. <a href="https://python.langchain.com/docs/modules/agents/" target="_blank" rel="noopener noreferrer">LangChain Agents</a>
and <a href="https://docs.llamaindex.ai/en/stable/use_cases/agents.html" target="_blank" rel="noopener noreferrer">LlamaIndex Agents</a>
make it easy to develop such pipelines. You can for example instruct the &quot;Agent&quot; to take one of two actions
conditionally as follows:
&quot;if the question is about counting or aggregations retrieve records from the GDBMS by converting <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to a Cypher query;
otherwise follow the RAG-U pipeline to retrieve chunks from documents.&quot; These are essentially
tools to develop a control logic over your LLM applications. It reminds me of the good old days when
there was a crazy hype around MapReduce-like &quot;big data systems&quot; and several initial works, such as <a href="https://dl.acm.org/doi/abs/10.1145/1376616.1376726" target="_blank" rel="noopener noreferrer">Pig Latin</a>
and <a href="https://www.usenix.org/legacy/event/nsdi11/tech/full_papers/Murray.pdf" target="_blank" rel="noopener noreferrer">Ciel</a>, immediately were addressing how to develop libraries/languages
over these systems to implement advanced control flows. Agents, or the recent <a href="https://github.com/langchain-ai/langgraph" target="_blank" rel="noopener noreferrer">LangGraph</a>,
seem like initial answers to the question of &quot;how do you program advanced LLM applications?&quot;</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-words">Final Words<a href="#final-words" class="hash-link" aria-label="Direct link to Final Words" title="Direct link to Final Words">​</a></h2><p>I want to conclude with two final points. First, there are many other applications that can
use LLMs and KGs beyond Q&amp;A. I don&#x27;t have space to cover
them here. Here is a <a href="https://arxiv.org/pdf/2306.08302.pdf" target="_blank" rel="noopener noreferrer">survey paper</a> that attempts to organize
the work in this space. The topics vary from how KGs can be used to train better LLMs to
how LLMs can be used to construct KGs to how one could embed both text and KG triples together as vectors
to better train LLMs.</p><p>Second, I listed 3 possible answers for the &quot;what additional data&quot;
design decision and 3 possible answers for &quot;how to fetch&quot; design decision. I further mentioned different
graph-based heuristics to extract chunks (or triples) once you can link the information in the unstructured
documents to each other through a KG. Many combinations of these design decisions and many other graph heuristics
are not yet explored. So there is quite a lot to explore in this space. The overall impression I was left
with was that we need more technically deep material in the space, which will only come through rigorous evaluations
of these RAG systems on standard benchmarks, as done in SIGIR or ACL publications.
I went through SIGIR 2023 publications and did not find work on a Q&amp;A system that uses LLMs + KGs
similar to the approaches I covered here. I hope to see such papers in 2024.</p><div class="footnotes"><hr><ol><li id="fn-1-c9223b">In this post I&#x27;m only covering approaches
that ultimately use retrieve some unstructured data (or a transformation of it) to put it
into LLM prompts. I am not covering approaches that query a pre-existing KG directly and use the records
in it as additional data into a prompt. See <a href="https://gradientflow.com/boosting-llms-with-external-knowledge-the-case-for-knowledge-graphs/" target="_blank" rel="noopener noreferrer">this post</a> by Ben Lorica
for an example. The 3 point bullet point after the &quot;Knowledge graphs significantly
enhance RAG models&quot; describes such an approach. According to my organization of RAG approaches,
such approaches would fall under RAG using structured data, since KGs are structured records.<a href="#fnref-1-c9223b" class="footnote-backref">↩</a></li><li id="fn-2-c9223b">The term sa-tree stands for &quot;spatial approximation&quot;, which refers to the following fact.
Exact spatial indices like kd-trees are balanced and divide a d-dimensional space into &quot;equal&quot; sub-spaces (not in volume but
in the number of vectors that are contained in the sub-spaces). Instead, sa-trees divide the space approximately and are not
necessarily balanced but sa-trees return exact answers. <a href="#fnref-2-c9223b" class="footnote-backref">↩</a></li><li id="fn-3-c9223b">In DeepDive, you would write extractors for the type
of triples you wanted to extract manually and DeepDive would use them in combination as part of a model
to extract high quality triples. Or you can just default to thinking hard about what you want to extract,
so what type of questions you want to answer in your RAG system, and based on those give example documents
and triples and train a specialized model. <a href="#fnref-3-c9223b" class="footnote-backref">↩</a></li><li id="fn-4-c9223b">SpanMarker is a recent approach for training powerful Named Entity Recognition models and is tightly implemented on top of the Transformers library by Hugging Face. It is based on the <a href="https://arxiv.org/pdf/2109.06067.pdf" target="_blank" rel="noopener noreferrer">PL-Marker paper</a>. The idea is to train a model that can detect NER entities from a large corpus of documents., label them with their types and map these types to the required triples as per your business domain.<a href="#fnref-4-c9223b" class="footnote-backref">↩</a></li></ol></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/llms">llms</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/llms-graphs-part-1">RAG Using Structured Data: Overview &amp; Important Questions</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-04T00:00:00.000Z" itemprop="datePublished">January 4, 2024</time> · <!-- -->25 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/team.jpg" alt="Semih Salihoğlu"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Semih Salihoğlu</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of Kùzu Inc. &amp; Associate Prof. at UWaterloo</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>During the holiday season, I did some reading on
LLMs and specifically on the techniques that use LLMs together with graph databases and knowledge graphs.
If you are new to the area like me, the amount of activity on this topic on social
media as well as in research publications may have intimidated you.
If so, you&#x27;re exactly my target audience for this new blog post series I am starting.
My goals are two-fold: </p><ol><li><em>Overview the area</em>: I want to present what I learned with a simple and consistent terminology and at
a more technical depth than you might find in other blog posts. I am aiming a depth similar to what I aim when preparing
a lecture. I will link to many quality and technically satisfying pieces of content (mainly papers since the area is very researchy).</li><li><em>Overview important future work</em>: I want to cover several important future works in the space. I don&#x27;t
necessarily mean work for research contributions but also simple approaches to experiment with if you are
building question answering (Q&amp;A) applications using LLMs and graph technology.</li></ol><p>This post covers the topic of retrieval augmented generation (RAG) using structured data. Then, in a follow up post,
I will cover RAG using unstructured data, where
I will also mention a few ways people are building RAG-based Q&amp;A systems that use both structured and unstructured data.</p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>TL;DR: The key takeaways from this post are:</div><div class="admonitionContent_S0QG"><ul><li><strong>RAG overview</strong>: RAG is a technique to fill the knowledge gap of LLMs using private data. RAG systems
use  private structured records stored in a database and/or unstructured data in text files. </li><li><strong>Impressive simplicity and effectiveness of developing a natural language interface over your database using LLMs</strong>: In the pre-LLM era, the amount of engineering effort
to develop a pipeline that delivered a natural language interface over your database was <em>immense</em>. The
hard problem was to teach a model to <em>speak</em> SQL, Cypher, or SPARQL.
This contrasts sharply with the simplicity of developing similar pipelines now because LLMs already &quot;speak&quot; these languages.
The hard task now is for <em>developers to learn how to prompt LLMs</em> to get correct database queries. Furthermore, there is
evidence that LLMs, if prompted correctly, will generate a decent proportion of queries with impressive accuracy.  </li><li><strong>Lack of work that studies LLMs&#x27; ability to generate Cypher or SPARQL:</strong> Most technically-deep work on understanding
LLMs&#x27; ability to generate accurate high-level query languages is on SQL. We need more
work understanding the behavior of LLMs on the query languages of GDBMSs (like Cypher or SPARQL), specifically on recursive and union-of-join queries.</li><li><strong>Studying the effects of data modeling (normalization, views, graph modeling) on the accuracy of LLM-generated queries is important:</strong>
Many people are studying heuristics for prompting LLMs to increase their efficiency focusing on the syntax and the structure of providing
the schema and selection of examples in the prompt. An important and under-studied
problem is the effects of data modeling choices on the accuracy of the queries generated by LLMs. I point to <a href="https://arxiv.org/pdf/2311.07509.pdf" target="_blank" rel="noopener noreferrer">one interesting paper</a> in this space and raise several questions related to
normalizations and use of views in relational modeling and comparisons with graph modeling approaches. </li></ul></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="killer-app-retrieval-augmented-generation">Killer App: Retrieval Augmented Generation<a href="#killer-app-retrieval-augmented-generation" class="hash-link" aria-label="Direct link to Killer App: Retrieval Augmented Generation" title="Direct link to Killer App: Retrieval Augmented Generation">​</a></h2><p>Let&#x27;s review the killer application of LLMs in enterprises.
The application is ultimately Q&amp;A over private enterprise data. Think of a chatbot to which you
can ask natural language questions (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>), such as: &quot;Who is our top paying customer from Waterloo?&quot;,
or &quot;What are data privacy regulations in Canada we need to comply with?&quot;
and get back natural language answers (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>).
LLMs, out of the box, cannot answer these questions because they have a <em>knowledge gap</em>.
For example, LLMs never had any access to your sales records when they were trained.
Therefore, they need to retrieve or be provided with
extra information from private data sources of the enterprise.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-note-on-the-term-rag">A note on the term RAG<a href="#a-note-on-the-term-rag" class="hash-link" aria-label="Direct link to A note on the term RAG" title="Direct link to A note on the term RAG">​</a></h3><p>There seems to be tremendous interest in building systems that combine a traditional
information retrieval component, e.g., one that looks up some documents from
an index, with a natural language generator component, such as an LLM. The term for such systems is
<em>Retrieval Augmented Generation</em> (RAG).
The term is coined in <a href="https://arxiv.org/pdf/2005.11401.pdf" target="_blank" rel="noopener noreferrer">this paper</a> to refer
to the method of fine-tuning an LLM with additional information, i.e.,
using this additional data to train a new variant of the LLM.
The original usage form in the paper is &quot;RAG models&quot;. Nowadays it is used in a variety of ways,
such as, &quot;RAG system&quot;, &quot;RAG-based system&quot;, &quot;RAG does X&quot;, or
&quot;Building RAG with Y&quot;. RAG often does not refer to fine-tuning LLMs any more. Instead, it
refers to providing LLMs with private data along with the question to fix the knowledge gap.
Even systems that simply use an LLM to convert a
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to SQL or Cypher query and simply return the results of the query
are called &quot;RAG systems&quot; in some documentations. I will use the term in this broader sense.</p><p>You can build RAG-based Q&amp;A systems by using structured and/or unstructured
data. The high-level views of these systems look like this:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/qa-over-enterprise-data-c63fb036791e4a0ec1f24d802d50254e.png" width="600" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag-using-structured-data-text-to-high-level-query">RAG Using Structured Data: Text-to-High-level-Query<a href="#rag-using-structured-data-text-to-high-level-query" class="hash-link" aria-label="Direct link to RAG Using Structured Data: Text-to-High-level-Query" title="Direct link to RAG Using Structured Data: Text-to-High-level-Query">​</a></h2><p><em>Note: If you are familiar with how to develop RAG systems with LangChain and LlamaIndex, you can directly skip
to the &quot;<a href="#how-good-are-llms-in-generating-high-level-queries">How Good are LLMs in Generating High-level Queries</a>&quot; part that
reflects on the reading I did on RAG using structured data.</em></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">​</a></h3><p>Many blog posts and several papers concern Q&amp;A systems that simply convert
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to a high-level query languge, such as SQL, Cypher, or SPARQL, using an LLM.
The figure below describes the overall approach:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/rag-using-structured-data-4e7c4e780c6a85b5664a3aa3f3f6c5a9.png" width="600" class="img_ev3q"></div><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, the schema of a database, and optionally
some example natural language question and high-level query examples, are given
to the LLM as a prompt.
The terms &quot;no shot&quot;, &quot;one shot&quot;, or &quot;few shot&quot; refer to the number of examples provided
in the prompt. Depending on the underlying database, the schema may contain
columns of relational tables and their descriptions, or labels of nodes and edges
of a graph database. Using <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, the database schema, and optionally
some examples, the LLM generates
a database query, such as SQL or Cypher. The system runs this query against the
DBMS and returns back the query result or using the LLM again, converts
the query result back to a natural language answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. </p><p><strong>Let us pause here to appreciate one thing:</strong> For many decades, the database community has studied the problem
of converting <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to SQL (aka &quot;text-to-SQL&quot;). Here is a good recent <a href="https://link.springer.com/article/10.1007/s00778-022-00776-8" target="_blank" rel="noopener noreferrer">survey paper</a>
that covers only the deep network-based approaches and <a href="https://www.nowpublishers.com/article/Details/DBS-078" target="_blank" rel="noopener noreferrer">a more extensive survey/book</a>
on the broader topic of natural language interfaces to databases.
Neither of these surveys cover any work that directly uses LLMs such as GPT models,
which are quite recent developments. Take any of the work covered in these surveys and
you&#x27;ll find an approach that requires significant engineering to build the pipeline shown in the above figure.
There exist several pre-LLM text-to-SQL systems (e.g., <a href="https://www.vldb.org/pvldb/vol9/p1209-saha.pdf" target="_blank" rel="noopener noreferrer">ATHENA</a>
or <a href="https://download.hrz.tu-darmstadt.de/pub/FB20/Dekanat/Publikationen/UKP/76500354.pdf" target="_blank" rel="noopener noreferrer">BELA</a>).
For example, most of the pre-LLM approaches that use deep learning require
hard work <em>to teach a model how to &quot;speak&quot; SQL</em> using large
corpora of tables and (question, query) examples, such as <a href="https://arxiv.org/abs/1709.00103" target="_blank" rel="noopener noreferrer">WikiSQL</a> or <a href="https://github.com/taoyds/spider" target="_blank" rel="noopener noreferrer">Spider</a>.
People had to solve and glue-together solutions to many technical problems, such as parsing the question,
entity detection, synonym finding, string similarity, among others.
Post-LLM approaches require <em>none</em> of these efforts because LLMs, such as GPT-4, already speak SQL, Cypher, and SPARQL out of the box, having been exposed to them in their pretraining.
Nowadays, the hard problem now is for developers <em>to learn how to prompt LLMs</em> so that
LLMs generate correct queries. I&#x27;ll say more about this problem. In contrast, building the above pipeline requires much less effort as
I&#x27;ll show next.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="simplicity-of-developing-rag-systems-langchain-and-llamaindex">Simplicity of Developing RAG Systems: LangChain and LlamaIndex<a href="#simplicity-of-developing-rag-systems-langchain-and-llamaindex" class="hash-link" aria-label="Direct link to Simplicity of Developing RAG Systems: LangChain and LlamaIndex" title="Direct link to Simplicity of Developing RAG Systems: LangChain and LlamaIndex">​</a></h3><p>If you have been following the developments in the LLM space, you will not be surprised to hear that nowadays people build
Q&amp;A systems that convert <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to a high-level query language using two common tools:
(i) <a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a>; and (ii) <a href="https://www.llamaindex.ai/" target="_blank" rel="noopener noreferrer">LlamaIndex</a>.
The same tools also integrate with the underlying storage system to load and retrieve your data. To make this more concrete, let me review the <a href="https://python.langchain.com/docs/use_cases/graph/graph_kuzu_qa" target="_blank" rel="noopener noreferrer">Kùzu-LangChain integration</a>, similar to the integrations found in other GDBMSs. You as a programmer have very little to do: you prepare your Kùzu
database <code>db</code> and load your data into it, wrap it around a <code>KuzuGraph</code> and <code>KuzuQAChain</code> objects in Python and you have
a text-to-Cypher pipeline:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> kuzu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chains </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> KuzuQAChain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat_models </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain_community</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">graphs </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> KuzuGraph</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">db </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> kuzu</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Database</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;test_db&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">//</span><span class="token plain"> create your graph </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> needed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">graph </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> KuzuGraph</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">db</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> KuzuQAChain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_llm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ChatOpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> graph</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">graph</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> verbose</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Who played in The Godfather: Part II?&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>I am following the example application in this <a href="https://python.langchain.com/docs/use_cases/graph/graph_kuzu_qa" target="_blank" rel="noopener noreferrer">documentation</a>,
which uses a database of movies, actors, and directors. </p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Output:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> Entering new  chain</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Generated Cypher:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MATCH </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">p:Person</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">-</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">:ActedIn</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">m:Movie </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">name: </span><span class="token string" style="color:#e3116c">&#x27;The Godfather: Part II&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> RETURN p.name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Full Context:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;p.name&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Al Pacino&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">, </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;p.name&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Robert De Niro&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> Finished chain.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token string" style="color:#e3116c">&#x27;Al Pacino and Robert De Niro both played in The Godfather: Part II.&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The &quot;chain&quot; first generated a Cypher query using <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
Behind the curtain, i.e., inside the KuzuQAChain code,
a GPT model was given the following prompt:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Generate Cypher statement to query a graph database.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Instructions:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Use only the provided relationship types and properties </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> the schema.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Do not use any other relationship types or properties that are not provided.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Schema:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node properties: </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;properties&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;STRING&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;label&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Movie&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">, </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;properties&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;name&#x27;</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;STRING&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">, </span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;birthDate&#x27;</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;STRING&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;label&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Person&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Relationships properties: </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;properties&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">, </span><span class="token string" style="color:#e3116c">&#x27;label&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ActedIn&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Relationships: </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;(:Person)-[:ActedIn]-&gt;(:Movie)&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Note: Do not include any explanations or apologies </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> your responses.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Do not respond to any questions that might ask anything </span><span class="token keyword" style="color:#00009f">else</span><span class="token plain"> than </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> you to construct a Cypher statement.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Do not include any text except the generated Cypher statement.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The question is:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Who played </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> The Godfather: Part II?</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Indeed, if you copy this prompt and paste it in <a href="https://chat.openai.com/" target="_blank" rel="noopener noreferrer">chatGPT&#x27;s browser interface</a>,
you will get the same or very similar Cypher query. The important point is: that&#x27;s all
the coding you have to do to build a natural language interface that can query your database.
You ultimately construct a string prompt that contains <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, some
instructions, and schema of the database, and the LLM will generate a query for you.
The <code>KuzuGraph</code> and <code>KuzuQAChain</code> are simple wrappers to do just that.
If you want to play around with how well this works on other datasets,
we have this pipeline implemented in Kùzu&#x27;s browser frontend <a href="https://kuzudb.com/docusaurus/kuzuexplorer/" target="_blank" rel="noopener noreferrer">KùzuExplorer</a>. </p><p>That is, for any database you have in Kùzu, you get a natural language interface over it in
KùzuExplorer (just click the &quot;robot icon&quot; on the left panel).
You can develop similar pipelines with other GDBMSs using similar interfaces (<em>though I recommend using Kùzu as it will be the
simplest to get started</em> 😉: <em>Unlike other GDBMSs, Kùzu is embeddable and requires no server set up</em>).
If you instead want to build Q&amp;A systems over your RDBMSs, you can use
LangChain&#x27;s <a href="https://python.langchain.com/docs/use_cases/qa_structured/sql#case-2-text-to-sql-query-and-execution" target="_blank" rel="noopener noreferrer">SQLDatabaseChain</a> and
<a href="https://python.langchain.com/docs/use_cases/qa_structured/sql#case-3-sql-agents" target="_blank" rel="noopener noreferrer">SQLAgent</a> or
LlamaIndex&#x27;s <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html#part-1-text-to-sql-query-engine" target="_blank" rel="noopener noreferrer">NLSQLTableQueryEngine</a>. The level of simplicity is similar to the example I presented. In practice, it is unlikely that your chatbot or search engine will be as simple
as the above example where the application interacts with the LLM only once. If you want
to interact with the LLM multiple times and conditionally take one action over another action etc.,
LangChain and LlamaIndex also provide ways to do that through their &quot;Agents&quot; (see <a href="https://python.langchain.com/docs/modules/agents/" target="_blank" rel="noopener noreferrer">LangChain Agents</a> and <a href="https://docs.llamaindex.ai/en/stable/use_cases/agents.html" target="_blank" rel="noopener noreferrer">Llama Index Agents</a>).</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-good-are-llms-in-generating-high-level-queries">How Good Are LLMs in Generating High-Level Queries?<a href="#how-good-are-llms-in-generating-high-level-queries" class="hash-link" aria-label="Direct link to How Good Are LLMs in Generating High-Level Queries?" title="Direct link to How Good Are LLMs in Generating High-Level Queries?">​</a></h3><p>Although building a text-to-high-level-query-language pipeline is now very simple with LLMs,
simplicity <strong>does not</strong> mean quality. Indeed, people building these systems are now faced with the following two important questions: </p><ol><li><em>How accurate are the high-level queries that LLMs generate?</em></li><li><em>How, e.g., through what types of prompts or data modeling, can we increase the accuracy of the
queries generated by LLMs?</em></li></ol><p>Here are several papers on this that I suggest reading:</p><ol><li><em><a href="https://arxiv.org/pdf/2303.13547.pdf" target="_blank" rel="noopener noreferrer">A comprehensive evaluation of ChatGPT’s zero-shot Text-to-SQL capability</a></em> from Tsinghua University and University of Illinois at Chicago. </li><li><em><a href="https://arxiv.org/pdf/2204.00498.pdf" target="_blank" rel="noopener noreferrer">Evaluating the Text-to-SQL Capabilities of Large Language Models</a></em> from researchers from Cambridge and universities and institutes from Montréal.</li><li><em><a href="https://arxiv.org/pdf/2308.15363.pdf" target="_blank" rel="noopener noreferrer">Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation</a></em> from Alibaba Group.</li><li><em><a href="https://arxiv.org/pdf/2305.12586.pdf" target="_blank" rel="noopener noreferrer">Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies</a></em> from Yale, Columbia, and Allen Institute for AI.</li><li><em><a href="https://arxiv.org/pdf/2305.11853.pdf" target="_blank" rel="noopener noreferrer">How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings</a></em> from Ohio State</li><li><em><a href="https://arxiv.org/pdf/2311.07509.pdf" target="_blank" rel="noopener noreferrer">A Benchmark to Understand the Role of Knowledge Graphs on LLM&#x27;s Accuracy for Q&amp;A on Enterprise SQL Databases</a></em> from data.world.</li></ol><p>These papers are either entirely or <em>almost</em> entirely evaluation-only papers that experiment with very detailed approaches of prompting LLMs
to generate SQL queries. First, let me say that the general message these
papers give (maybe except the last one) is that LLMs are pretty good. With right prompting (or even with basic prompting)
they do very well on these benchmarks. I see accuracy rates over 85% on the Spider benchmark in several papers. These are clearly
better numbers than what pre-LLM state-of-the-art systems achieved. This should be impressive to many.</p><p>Second, the set of techniques are too detailed to cover here but some example heuristics
these papers experiment with include the following: (i) the syntax used for providing the schema
(apparently putting &quot;the pound sign <code>#</code> to differentiate prompt from response in examples yields impressive performance gains&quot; 😀 go figure); (ii)
the number and selection of example (question, SQL) pairs, e.g., apparently there is a sweet spot in the number
of examples to provide; or (iii) the effects of standardizing the text in the prompt, e.g., indenting and using all lower case letters consistently
(apparently has minor but some effect). Yes, as interesting and important it is to learn how to use LLMs better, I still
can&#x27;t escape the following thought before going to bed: somewhere out there, some advisor might be torturing some graduate student
to check if the magical box produces better SQL with a pound sign vs double slashes!</p><p>Most work I found is on generating SQL.
In contrast, I found no papers that do similar prompting study for query languages
of GDBMS though I ran into two papers that are providing benchmarks for query languages of GDBMSs:
(i) <a href="https://arxiv.org/abs/2309.16248" target="_blank" rel="noopener noreferrer">SPARQL</a>; and (ii) <a href="https://dl.acm.org/doi/pdf/10.1145/3511808.3557703" target="_blank" rel="noopener noreferrer">Cypher</a>).
So a low-hanging fruit future work is the following:</p><p><em>Important Future Work 1: Similar prompting studies for query languages of graph DBMSs with a focus on recursive and unions of joins queries.</em>:
In contrast to SQL queries, here, one should study various recursive queries that the query languages of GDBMSs are particularly good
at and union-of-join queries which are asked by omitting labels in the query languages of GDBMSs.
For example if you want to ask all connections between
your <code>User</code> nodes and User can have many relationships, such as <code>Follows</code>, <code>SentMoneyTo</code>, or <code>SameFamily</code>,
you would have to write 3 possible join queries in SQL and union them. Instead, you can write this query
with a very simple syntax in Cypher as
<code>MATCH (a:User)-[e]-&gt;(b:User)</code>, where the omissions of the label on the relationship <code>e</code> indicates searching over
all possible joins.<sup id="fnref-1-a733ad"><a href="#fn-1-a733ad" class="footnote-ref">1</a></sup> </p><p>As a side note: In the context of any query language, including SQL, questions that require sub-queries are of particular
interest as they are generally harder to write. Some of the papers I read had sections analyzing the performance of
LLMs on nested queries but the focus was not on these. In prior literature there are papers written solely on text-to-SQL generation for
nested queries (e.g., see <a href="https://www.vldb.org/pvldb/vol13/p2747-sen.pdf" target="_blank" rel="noopener noreferrer">the ATHENA++ paper</a>). I am certain someone
somewhere is already focusing solely on nested queries and that&#x27;s a good idea.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dataworld-paper-and-some-interesting-questions">data.world Paper and Some Interesting Questions<a href="#dataworld-paper-and-some-interesting-questions" class="hash-link" aria-label="Direct link to data.world Paper and Some Interesting Questions" title="Direct link to data.world Paper and Some Interesting Questions">​</a></h2><p>In the remainder of the post I want to review <a href="https://arxiv.org/pdf/2311.07509.pdf" target="_blank" rel="noopener noreferrer">the benchmark paper</a> from <code>data.world</code> that focuses on text-to-SQL using LLMs. Unlike other papers out there that
study the effects of different prompting heuristics, this paper studies the <em>effects of data modeling
on the accuracy of SQL queries generated by LLMs</em>, which is closely related to GDBMSs. </p><p>Specifically, this paper is an evaluation of the performance of GPT-4 in generating SQL using no examples, i.e., zero-shot,
with basic prompting over a standardized insurance database schema
called The <a href="https://www.omg.org/spec/PC/1.0/About-PC" target="_blank" rel="noopener noreferrer">OMG Property and Casualty Data Model</a>.
See Figure 1 in the paper (omitted here) for the conceptual schema, which consists of classes such as
Policy, Account, Claims, Insurable Object, among others, and their relationships.
The paper has a benchmark of 43 natural language questions and compares 2 approaches to generate the SQL query.
The below figure shows an overview of these approaches for reference:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/two-sql-generation-approaches-cceca4532513a6bb7ccae29e3f3ca94f.png" width="600" class="img_ev3q"></div><ol><li>Direct SQL Generation: In this approach, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> and the relational schema of the OMG database is given
to GPT-4. The schema is given in terms of <code>CREATE TABLE</code> statements, such as:<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">TABLE</span><span class="token plain"> Claim</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Claim_Identifier     </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain">  </span><span class="token operator" style="color:#393A34">NOT</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">NULL</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Catastrophe_Identifier </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain">  </span><span class="token boolean" style="color:#36acaa">NULL</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Claim_Open_Date      </span><span class="token keyword" style="color:#00009f">datetime</span><span class="token plain">  </span><span class="token boolean" style="color:#36acaa">NULL</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><span class="token keyword" style="color:#00009f">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Claim_Identifier </span><span class="token keyword" style="color:#00009f">ASC</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><span class="token keyword" style="color:#00009f">FOREIGN</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Catastrophe_Identifier</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">REFERENCES</span><span class="token plain"> Catastrophe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Catastrophe_Identifier</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>The full schema statements can be found <a href="https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/DDL/ACME_small.ddl" target="_blank" rel="noopener noreferrer">here</a>.
GPT-4 is asked to generate a SQL query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">SQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> to answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
Copy-pasted from the paper, these prompts look as follows:<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Given the database described by the following DDL:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;INSERT CREATE STATEMENTS FOR SCHEMA&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Write a SQL query that answers the following question. Do not explain the query. return just the query, so it can be run</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">verbatim from your response.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Here’s the question:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;INSERT QUESTION&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li>Indirect SQL Generation via Graph Modeling/SPARQL: In this approach, instead of the relational schema of the database, the same
database is modeled as an <em><a href="https://www.w3.org/OWL/" target="_blank" rel="noopener noreferrer">OWL ontology</a></em> (OWL is short for Web Ontology Language).
Ontology is another term for schema when modeling data as graph as classes and relationships between them. OWL is a W3C standard
and part of the RDF technology stack so OWL ontologies are expressed as a set RDF triples, such as:<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">in:Claim rdf:type owl:Class ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      rdfs:isDefinedBy &lt;http://data.world/schema/insurance/&gt; ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      rdfs:label &quot;Claim&quot; .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">in:claimOpenDate rdf:type owl:DatatypeProperty ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              rdfs:domain in:Claim ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              rdfs:range xsd:dateTime ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              rdfs:isDefinedBy &lt;http://data.world/schema/insurance/&gt; ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              rdfs:label &quot;Claim Open Date&quot; .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">in:hasCatastrophe rdf:type owl:ObjectProperty ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               rdfs:domain in:Claim ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               rdfs:range in:Catastrophe ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               rdfs:isDefinedBy &lt;http://data.world/schema/insurance/&gt; ;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               rdfs:label &quot;has catastrophe&quot; .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>The full ontology can be found <a href="https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/ontology/insurance.ttl" target="_blank" rel="noopener noreferrer">here</a>.
GPT-4 is then asked to generate a SPARQL query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>P</mi><mi>A</mi><mi>R</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SPARQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">SP</span><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight">RQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>, instead of SQL, for the same <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. The full prompt, again copy-pasted
from the paper with some simplifications, looks like this:<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Given the OWL model described in the following TTL file:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;INSERT OWL ontology as triples&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Write a SPARQL query that answers the question. Do not explain the query. return just the query, so it can be run verbatim from your response.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Here’s the question:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;INSERT QUESTION&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>As a last step, the authors have a direct mapping from <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>P</mi><mi>A</mi><mi>R</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SPARQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">SP</span><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight">RQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> to a SQL query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">SQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>. This is a quite straigh-forward step
as the modeling as an ontology vs relational schema have direct translations from classes and properties to tables and columns.</li></ol><p>An interesting comparison. There is some intuition for why one would be interested in the effectiveness of
query generation through an ontology because one of the well-known
pre-LLM text-to-SQL papers <a href="https://www.vldb.org/pvldb/vol9/p1209-saha.pdf" target="_blank" rel="noopener noreferrer">ATHENA</a> did something similar.
Instead of SPARQL they had another query language over an ontology called Ontology Query Language, which
was then mapped to SQL. </p><p>The results are even more interesting. The authors categorize their 43 questions into
4 quadrants based on 2 dimensions: </p><ul><li>Low vs high <strong>question</strong> complexity: Questions that require only simple projections
are low complexity. Those that require aggregations or math functions are high complexity.</li><li>Low vs high <strong>schema</strong> complexity: Questions whose SQL queries require up to 4 tables are low schema complexity. Those that
require 5 or more joins are high schema complexity. </li></ul><p>The accuracy results are shown below. Accuracy here is &quot;execution accuracy&quot; meaning that  only the answers of the queries
are checked against the ground truth answer. That is, even if the SQL query GPT-4 generated was actually not correct
but by luck it computed the correct answers the paper takes it as correct (apparently happens very rarely in this study).</p><table><thead><tr><th>Overall: 16.7% vs 54.2%</th><th>Low Schema Complexity</th><th>High Schema Complexity</th></tr></thead><tbody><tr><td><b>Low Question Complexity</b></td><td>37.4% vs 66.9%</td><td>0% vs 38.7%</td></tr><tr><td><b>High Question Complexity</b></td><td>25.5% vs 71.1%</td><td>0% vs 35.7%</td></tr></tbody></table><p>Overall, the indirect SQL generation method through SPARQL is much more effective in this zero-shot setting.
Not surprisingly, questions that require 5 or more joins are harder regardless of the
method used and direct SQL cannot get any of those questions right. These are interesting
results for an initial study on the effects of data modeling on LLMs&#x27; accuracy on generating database queries.
These results should give many researchers and practitioners ideas about how to replicate
and validate/invalidate similar results under different settings, e.g., with few-shot
examples and under different databases.</p><p><strong>That said, one should ask, why?</strong> In fact, we should all be suspicious that merely modeling the
same set of records with a different abstraction should have any visible effects. After all, by modeling
the same records differently, one does not obtain or lose information. So if and when LLMs are smart enough,
they shouldn&#x27;t care how the data was modeled. But for now, if a pound sign can make a difference,
we should not be surprised modeling choices can have large impacts. As such, it is healthy to be suspicious
and ask why. These motivate a few important questions I think are worth studying. My premise
is that somehow if the differences are this large, it must be that the task for GPT-4 got simpler when
asked to generate a SPARQL query. I can hypothesize about a few possible reasons for this: </p><ul><li><p><em>Some queries require fewer tokens to write in SPARQL</em>: One difference the query languages
of GDBMSs often have is that certain equality conditions are implicit in the syntax, which
means their <code>WHERE</code> clauses are simpler for some queries. For example if you wanted to return
the names of the Catastrophe that Claim with ID Claim1 has, in SPARQL you can write it as:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT ?name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE { &lt;in:Claim1&gt; in:hasCatastrophe ?catastrophe,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ?catastophe in:catastropheName ?name}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In SQL you would write:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT Catastrophe_Name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM Claim, Catastrophe</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE Claim.Catastrophe_Identifier = Catastrophe.Catastrophe_Identifier AND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Claim.Claim_Identifier = Claim1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Note that the <code>Claim.Claim_Identifier = Claim1</code> equality condition is implicit in the <code>&lt;in:Claim1&gt; in:hasCatastrophe ?catastrophe</code> triple
and the <code>Claim.Catastrophe_Identifier = Catastrophe.Catastrophe_Identifier</code> condition is implicit in the fact that <code>?catastrophe</code> appears
both in the first and second triples in the SPARQL query. Such implicit equality conditions are common in the languages of
graph query languages especially when expressing joins. For example in Cypher you can omit all join conditions in WHERE clauses as long
as those joins have been pre-defined to the system as relationships. Instead you join records through the <code>(a)-[e]-&gt;(b)</code> syntax.
It&#x27;s unclear how much this could matter but it is an immediate advantage of SPARQL that can explain why complex join queries are easier to generate
in SPARQL than SQL.  </p><p><strong>Side note</strong>: On the flip side, SPARQL can be more verbose in projections. For example, if you wanted to return the number, open and close
dates of every claim, you&#x27;d write the following SQL query:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT Claim_Number, Claim_Open_Date, Claim_Close_Date</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM Claim</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In SPARQL, you&#x27;d have to write both the names of the property you want to project and give it an additional variable as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT ?number, ?open_date, ?close_date</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE { ?claim in:claimNumber ?number,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ?claim in:claimOpenDate ?open_date,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ?claim in:claimCloseDate ?close_date</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li></ul><ol start="2"><li><em>Graph modeling gives explicit names to foreign keys:</em> There is a reason that database courses teach database modeling to students
using graph-based models, such as Entity-Relationship or UML models. First, humans think of the world
as objects/entities and their relationships. In some sense, these are higher-level models where relationships
between objects are denoted explicitly with explicit names (instead of as less explicit foreign key constraints).
For example, the implicit connection between Claims and
Catastrophes through the <code>FOREIGN KEY (Catastrophe_Identifier) REFERENCES Catastrophe(Catastrophe_Identifier)</code>
constraint was given an explicit English name: <code>hasCatastrophe</code> in the ontology. This explicitness may make
it easier for LLMs to understand the schema and generate SPARQL queries.</li></ol><p>Both of these are qualitative hypotheses. however, there is a more immediate
reason the authors of this paper may have obtained such major differences between the two approaches they tried.
Intentionally or unintentionally, their ontology is simplified significantly compared to the relational schema they have.
For example, the Claim relation has <code>Claim_Reopen_Date</code> and <code>Claim_Status_Code</code> properties which are removed from the ontology.
Many such properties from the relations seem to have been removed, and the ontology overall looks simpler.
There are also several differences between the ontology and the relational schema that are confusing. For example
the <a href="https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/ontology/insurance.ttl" target="_blank" rel="noopener noreferrer">ontology</a>
has a class <code>Agent</code> and <code>Policy</code> objects are <code>in:soldByAgent</code> by some Agent objects (see lines 20 and 92). I cannot
see corresponding relations or columns in the <a href="https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/DDL/ACME_small.ddl" target="_blank" rel="noopener noreferrer">relational schema</a>. Unless I am missing something about how the prompts were given,
these are also likely to have important effects on the results and someone should fix and obtain new results
in a more fair comparison.</p><p>Let me next raise several high-level questions that I think are important:</p><p><em>Important Future Work 2: Rules of thumbs in data modeling to make LLM-generated queries more accurate.</em>
I think the higher-level question of studying the effects of data modeling in more depth is a very good direction.
As LLMs get smarter, I would expect that the presence/absence of a pound sign or the style of English
should matter less. These look more like syntactic differences that can be automatically detected over time.
Modeling choices are more fundamental and relate to the clarity and understandibility of the records that will be queried by the LLM.
So identifying some rules of thumb here looks like the promising path forward. Let me list a few immediate questions one can study:</p><p><em>Important Future Work 2.1: Effects of normalization/denormalization.</em> If the shortcoming of GPT-4 is
generating queries with many joins, one way to solve this is to denormalize the relations into fewer
tables and study its effects. Again, I&#x27;m thinking of same records just modeled differently with fewer
tables. What happens if we reduce all data into a single table with dozens of columns and many value repetitions?
Now all possible joins would have been performed so we&#x27;d force the LLM to write a join-less query with
filters, distincts, and aggregations. What happens if we normalize the tables step-by-step until we
get to a well known form, such as <a href="https://en.wikipedia.org/wiki/Boyce%E2%80%93Codd_normal_form" target="_blank" rel="noopener noreferrer">Boyce-Codd Normal Form</a>? Do we consistently get better or worse accuracy?</p><p><em>Important Future Work 2.2: Use of views.</em> In relational modeling, views are an effective way to have higher
and simpler modeling of your records. Similar to a <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> -<!-- -->[LLM]<!-- -->-&gt; <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>P</mi><mi>A</mi><mi>R</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SPARQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">SP</span><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight">RQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> -<!-- -->[Direct Mapping]<!-- -->-&gt; <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">SQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> pipeline,
one can test the effectiveness of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> -<!-- -->[LLM]<!-- -->-&gt; <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>Q</mi><mi>L</mi><mo>−</mo><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mo>−</mo><mi>V</mi><mi>i</mi><mi>e</mi><mi>w</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SQL-over-Views}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">SQ</span><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">er</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">Vi</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> -<!-- -->[Direct Mapping]<!-- -->-&gt; <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>S</mi><mi>Q</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{SQL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">SQ</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> pipeline.</p><p><em>Important Future Work 3: Use of Cypher as intermediate query language to translate to SQL.</em> One reason to experiment with Cypher
in addition to SPARQL is that Cypher is, arguably, more similar to SQL than SPARQL but has the advantage that (common) join
conditions are implicit in the <code>(a)-[e]-&gt;(b)</code> node-arrow syntax. Yet Cypher does not have the verbosity of the SPARQL projections
I mentioned above (so you project properties the same way you project columns in SQL). In my world, all high-level query languages
look very similar to SQL, so eventually when LLMs are smart enough, or even today, I think these language differences
should have minor effects. However, graph query languages will likely continue to have major advantages when writing
recursive queries, as they have specialized syntax (e.g., Cypher has the Kleene star syntax) to do so. For those queries,
expressing first in Cypher and then mapping to SQL could lead to an advantage. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-words">Final Words<a href="#final-words" class="hash-link" aria-label="Direct link to Final Words" title="Direct link to Final Words">​</a></h2><p>Needless to say, in the next few years, the field will be flooded with work on how to
use LLMs to solve the text-to-high-level-query problem. Many rules of thumb will emerge
about how to prompt them correctly. The questions one can ask in this space is endless.
I can speculate about it a lot, but I think it&#x27;s plausible that
many of these rules of thumb, specifically the syntactic
differences in prompting, can become
obsolete very quickly as newer and more advanced LLMs that are better at speaking high-level database languages emerge.
For example, it&#x27;s plausible that people will stop showing LLMs example (question, query) pairs each time they ask them to generate
SQL once LLMs are better at speaking SQL.</p><p>However, the harder question of how to model the data so that its meaning is clear, and the
queries that need to be written, are simpler, is more likely to remain a challenge for a longer time. I would not be too optimistic
that there can emerge very clear answers to this question. How to model your data is part-art and part-science.
Yet, some studiable questions, such as the effects of normalization, use of views or generating Cypher for recursive queries,
can yield some important best practices that can be useful to developers building these systems.</p><p>In the next post, I will cover what I learned about RAG over unstructured data. Graphs and knowledge graphs are playing
a more interesting role in that space. Until then, happy new year to all!</p><div class="footnotes"><hr><ol><li id="fn-1-a733ad">SPARQL syntax is different but a similar advantage exists by omitting type constraints.<a href="#fnref-1-a733ad" class="footnote-backref">↩</a></li></ol></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/use-case">use-case</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/kuzu-0.1.0-release">Kùzu 0.1.0 Release</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-11-19T00:00:00.000Z" itemprop="datePublished">November 19, 2023</time> · <!-- -->10 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/kuzudb/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/team.jpg" alt="Kùzu Team"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/kuzudb/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Kùzu Team</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>We are very happy to release Kùzu 0.1.0 today! This is a major release with the following set of new features and improvements:</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/release">release</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Kùzu 0.1.0 Release" href="/docusaurus/blog/kuzu-0.1.0-release"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/kuzu-0.0.12-release">Kùzu 0.0.12 Release</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-10-31T00:00:00.000Z" itemprop="datePublished">October 31, 2023</time> · <!-- -->One min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/kuzudb/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/team.jpg" alt="Kùzu Team"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/kuzudb/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Kùzu Team</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>We release Kùzu 0.0.12, another minor release. This release fixes a bug that prevents the database to be opened in read-only mode on a read-only file system. It also adds support for INT128 data type.</p><p>For more detailed information about the changes in this release, please see <a href="https://github.com/kuzudb/kuzu/releases/tag/v0.0.12" target="_blank" rel="noopener noreferrer">here</a>.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/release">release</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/docusaurus/blog/page/2"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://join.slack.com/t/kuzudb/shared_invite/zt-1w0thj6s7-0bLaU8Sb~4fDMKJ~oejG_g" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/kuzudb" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@KuzuDB" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/410352593" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docusaurus/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/kuzudb/kuzu" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Kùzu Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/docusaurus/assets/js/runtime~main.990e818c.js"></script>
<script src="/docusaurus/assets/js/main.486ad7a4.js"></script>
</body>
</html>