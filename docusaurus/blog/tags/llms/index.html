<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">One post tagged with &quot;llms&quot; | Kùzu</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:url" content="https://kuzudb.com/docusaurus/blog/tags/llms"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="og:locale" content="en_US"><meta data-rh="true" name="og:type" content="article"><meta data-rh="true" name="og:site_name" content="Kùzu"><meta data-rh="true" name="og:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="twitter:site" content="@kuzudb"><meta data-rh="true" name="twitter:creator" content="@kuzudb"><meta data-rh="true" name="twitter:image" content="https://kuzudb.com/img/logo-u-with-orange-tick.jpg"><meta data-rh="true" property="og:title" content="One post tagged with &quot;llms&quot; | Kùzu"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/docusaurus/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://kuzudb.com/docusaurus/blog/tags/llms"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog/tags/llms" hreflang="en"><link data-rh="true" rel="alternate" href="https://kuzudb.com/docusaurus/blog/tags/llms" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XV0PE3XW33-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/docusaurus/blog/rss.xml" title="Kùzu RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/docusaurus/blog/atom.xml" title="Kùzu Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Kùzu" href="/docusaurus/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer"><link rel="stylesheet" href="/docusaurus/assets/css/styles.a72d597a.css">
<link rel="preload" href="/docusaurus/assets/js/runtime~main.29273660.js" as="script">
<link rel="preload" href="/docusaurus/assets/js/main.c8476cd5.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://kuzudb.com/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/docusaurus/img/kuzu-logo.png" alt="Kùzu" class="themedImage_ToTc themedImage--light_HNdA"><img src="/docusaurus/img/kuzu-logo-inverse.png" alt="Kùzu" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/docusaurus/installation">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docusaurus/blog/">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item">
            <a href="https://github.com/kuzudb/kuzu" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-github fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://discord.gg/jw7xN2ZhJB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-discord fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://twitter.com/kuzudb" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-twitter fa-xl"></i>
            </a>
            </div><div class="navbar__item">
            <a href="https://www.youtube.com/@KuzuDB" class="navbar__link navbar__link--social">
              <i class="fa-brands fa-youtube fa-xl"></i>
            </a>
            </div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All our posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-2">RAG Using Unstructured Data &amp; Role of Knowledge Graphs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/llms-graphs-part-1">RAG Using Structured Data: Overview &amp; Important Questions</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.1.0-release">Kùzu 0.1.0 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.12-release">Kùzu 0.0.12 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzuexplorer">KùzuExplorer: Visualizing Query Results and Schemas</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.11-release">Kùzu 0.0.11 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.10-release">Kùzu 0.0.10 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.9-release">Kùzu 0.0.9 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.8-release">Kùzu 0.0.8 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.7-release">Kùzu 0.0.7 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/iamgraphviz">IAMGraphViz: Visualizing AWS IAM Permissions with Kùzu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.6-release">Kùzu 0.0.6 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.5-release">Kùzu 0.0.5 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.4-release">Kùzu 0.0.4 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-pyg-remote-backend">Scaling Pytorch Geometric GNNs With Kùzu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.3-release">Kùzu 0.0.3 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/wcoj">Why (Graph) DBMSs Need New Join Algorithms: The Story of Worst-case Optimal Join Algorithms</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/kuzu-0.0.2-release">Kùzu 0.0.2 Release</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/factorization">Factorization &amp; Great Ideas from Database Theory</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/what-every-gdbms-should-do-and-vision">What Every Competent GDBMS Should Do (aka The Goals &amp; Vision of Kùzu</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/docusaurus/blog/meet-kuzu">Meet Kùzu 🤗</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;llms&quot;</h1><a href="/docusaurus/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/docusaurus/blog/llms-graphs-part-2">RAG Using Unstructured Data &amp; Role of Knowledge Graphs</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-01-15T00:00:00.000Z" itemprop="datePublished">January 15, 2024</time> · <!-- -->20 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://kuzudb.com/img/blog/team.jpg" alt="Semih Salihoğlu"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://cs.uwaterloo.ca/~ssalihog/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Semih Salihoğlu</span></a></div><small class="avatar__subtitle" itemprop="description">CEO of Kùzu Inc &amp; Associate Prof. at UWaterloo</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://kuzudb.com/docusaurus/blog/llms-graphs-part-1" target="_blank" rel="noopener noreferrer">In my previous post</a>,
I gave an overview of question answering (Q&amp;A) systems that use LLMs
over private enterprise data. I covered the architectures of these systems, the common tools
developers use to build these systems when the enterprise data used is structured,
i.e., data exists as records stored in some DBMS, relational or graph. I was referring to
these systems as <em>RAG systems using structured data</em>. In this post, I cover <em>RAG systems
that use unstructured data</em>, such as text files,
pdf documents, or internal html pages in an enterprise. I will refer to these as RAG-U systems
or sometimes simply as RAG-U (should have used the term RAG-S in the previous post!).</p><p>To remind readers, I decided to
write these two posts after doing a lot of reading in the space to understand the role of
knowledge graph (KGs) and graph DBMSs in LLM applications. My goals are (i) to overview the field to readers who want to get started
but are intimidated by the area; and (ii) point to several future work directions that I find
important.<sup id="fnref-1-c9223b"><a href="#fn-1-c9223b" class="footnote-ref">1</a></sup></p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>TL;DR: The key takeaways from this post are:</div><div class="admonitionContent_S0QG"><ul><li><strong>Two design decisions when preparing a RAG-U system are (i) &quot;What additional data&quot; to put in prompts; and (ii) &quot;How to store and fetch&quot; the additional data.</strong>: Explored options for types of additional data include chunks of texts, full documents, or automatically extracted triples from documents. There are different ways to store and fetch this additional data, such as use of vector indices. Many combinations of this design space are not yet explored.</li><li><strong>Standard RAG-U</strong>: A common design point, which I will call the standard RAG-U, is to add chunks of documents as additional data and store them in a vector index. I found some of the most technically deep and interesting future work directions in this space, e.g., extending vectors to matrices.</li><li><strong>An envisioned role for KGs in a RAG-U system is as a means to link chunks of text:</strong> If chunks can be linked to entities in an existing KG, then one can connect chunks to each other through the relationships in KG.
These connections can be exploited to retrieve more relevant chunks. This is a promising direction but
its potential benefits should be subjected to rigorously evaluation, e.g., as major SIGIR publications evaluate a new retrieval technique. It won&#x27;t pick up through commercial blog posts.</li><li><strong>What if an enterprise does not have a KG?</strong> The hope of using KGs to do better retrieval in absence of a pre-existing KG raises the question and never ending quest of <em>automatic knowledge graph construction</em>. This is a very interesting topic and most recent research here uses LLMs for this purpose but: (i) LLMs seem behind in extracting quality knowledge graph facts; and (ii) it&#x27;s not clear if use of LLMs for this purpose at scale is economically feasible.</li></ul></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag-u-overview">RAG-U Overview<a href="#rag-u-overview" class="hash-link" aria-label="Direct link to RAG-U Overview" title="Direct link to RAG-U Overview">​</a></h2><p>I will skip the overview of RAG systems, which I covered in <a href="https://kuzudb.com/docusaurus/blog/llms-graphs-part-1#a-note-on-the-term-rag" target="_blank" rel="noopener noreferrer">the previous post</a>.
The picture of RAG systems that use unstructured data looks as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/rag-unstructured-overview-9cf06430dbd5bc1a010aa69dd7b98f6a.png" width="600" class="img_ev3q"></div><p>An enterprise has a corpus of unstructured data, i.e., some documents with text.
As a preprocessing step (omitted from the figure), the information in these documents are indexed and
stored in some storage system. The figure labels the 4 overall steps in a RAG-U system:</p><ol><li>A natural language query <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> comes into the RAG-U system.</li><li>Parts of the corpus of unstructured data that is expected to be helpful in answering <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
is fetched from some storage system.</li><li>The fetched data along with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> given to an LLM.</li><li>LLM produces a natural language answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> for <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.</li></ol><p>Any system built along these 4 high-level steps needs to make two design choices:</p><p><strong>Design Choice 1: What is the additional data?</strong> Among the posts, documentation, and demonstrations
I have read, I have seen three designs:</p><ul><li>Chunks of documents</li><li>Entire documents</li><li>Triples extracted from documents</li></ul><p><strong>Design Choice 2: How to store and fetch the additional data?</strong> Here, I have seen the following designs:</p><ul><li>Vector Index</li><li>Vector Index + Knowledge Graph (stored in a GDBMS)</li><li>GDBMS (for storing triples)</li></ul><p>Many combinations of these two choices are possible and can be tried. Each choice
can effectively be understood as a <em>retrieval heuristic</em> to fetch quality content that can
help LLMs answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> more accurately.
I will cover a few of the ones that I have seen but others are certainly possible and should be tried by people
developing RAG-U systems.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="standard-rag-u-chunks-of-documents-stored-in-a-vector-index">Standard RAG-U: Chunks of Documents Stored in a Vector Index<a href="#standard-rag-u-chunks-of-documents-stored-in-a-vector-index" class="hash-link" aria-label="Direct link to Standard RAG-U: Chunks of Documents Stored in a Vector Index" title="Direct link to Standard RAG-U: Chunks of Documents Stored in a Vector Index">​</a></h2><p>Standard RAG-U is what you will read about in most places. Its design is as follows: (i) we split the text in the
documents into (possibly overlapping) &quot;chunks&quot;; (ii) we embed these chunks into vectors, i.e., high dimensional points, using
a text embedding model (many off-the-shelf open-source models exist from <a href="https://platform.openai.com/docs/guides/embeddings" target="_blank" rel="noopener noreferrer">OpenAI</a>, <a href="https://docs.cohere.com/reference/embed" target="_blank" rel="noopener noreferrer">Cohere</a>, and <a href="https://huggingface.co/blog/getting-started-with-embeddings" target="_blank" rel="noopener noreferrer">Hugging Face</a>);
and (iii) we store these vectors in a vector index. For example, see LangChain main documentation
on &quot;<a href="https://python.langchain.com/docs/use_cases/question_answering/" target="_blank" rel="noopener noreferrer">Q&amp;A with RAG</a>&quot; or LlamaIndex&#x27;s
&quot;<a href="https://docs.llamaindex.ai/en/stable/examples/low_level/oss_ingestion_retrieval.html" target="_blank" rel="noopener noreferrer">Building a RAG from Scratch</a>&quot; documentation.
The below figure shows the pre-processing and indexing steps of standard RAG-U:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/standard-rag-preprocessing-2ed0ed6a8e1e4583cc0036aa0e7a95f1.png" width="600" class="img_ev3q"></div><p><strong>First a note on vector indices:</strong> A vector index is one that indexes a
set of d-dimensional vectors and given a query vector w can answer several queries:
(i) <em>pure search</em>: does w exist in the index?; (ii) <em>k nearest neighbors</em>: return
the k vectors closest to w; or (iii) <em>range queries</em>: return vectors that are within
a radius r of w. There have been decades of work on this topic.
If d is very small, say 3 or 4, there are &quot;exact spatial indices&quot; like <a href="https://en.wikipedia.org/wiki/Quadtree" target="_blank" rel="noopener noreferrer">quad trees</a> (for 2D only), <a href="https://en.wikipedia.org/wiki/R-tree" target="_blank" rel="noopener noreferrer">r-trees</a>, or <a href="https://en.wikipedia.org/wiki/K-d_tree" target="_blank" rel="noopener noreferrer">k-d trees</a>.
These indices have good construction and query times when d is small but their performance degrades
fast when d increases and they quickly become impractical.
There have been some good work to index high-dimensional vectors as well.
<a href="https://dl.acm.org/doi/10.1007/s007780200060" target="_blank" rel="noopener noreferrer">SA-trees</a> by Navarro is the core
technique that underlies the nowadays popular indices, such as <a href="https://arxiv.org/abs/1603.09320" target="_blank" rel="noopener noreferrer">hierarchical navigable small-world graph (HNSW) indices</a>, which are extensions of <a href="https://www.sciencedirect.com/science/article/abs/pii/S0306437913001300" target="_blank" rel="noopener noreferrer">navigable small world (NSW)
indices</a>.
Navarro&#x27;s SA-tree index returns exact results as well<sup id="fnref-2-c9223b"><a href="#fn-2-c9223b" class="footnote-ref">2</a></sup> but does not have good query times.
In Navarro&#x27;s experiments, even for
relatively small dimensions such as 10-20, sa-tree can scan 10-100% of all vectors in the index
for queries that need to return less than 1% of the vectors.
SNW and HSNW instead are not exact indices. They are called approximate indices but they are not
even approximate in the sense of having any approximation guarantees in their query results.
They are heuristic-based indices that can index very high-dimensional vector and are fast
both in their construction and their query times. Further, their query results are shown to be quite accurate empirically.
HNSW indices are nowadays used by vector databases like <a href="https://www.pinecone.io/learn/series/faiss/hnsw/" target="_blank" rel="noopener noreferrer">Pinecone</a>
and <a href="https://weaviate.io/developers/weaviate/concepts/vector-index" target="_blank" rel="noopener noreferrer">Weaviate</a> or search engine libraries such as <a href="https://lucene.apache.org/core/9_1_0/core/org/apache/lucene/util/hnsw/HnswGraph.html" target="_blank" rel="noopener noreferrer">Lucene</a> in their vector indices.
To understand these indices, I highly suggest first reading the Navarro paper
paper, which is the foundation. It&#x27;s also a great example of a well-written database paper: one that
makes a very clear contribution and is explained in a very clean technical language.</p><p>Back to RAG-U. After the preprocessing step, the vector index that contains the chunks of documents is used
in a RAG-U system as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/standard-rag-overview-1a978709d941cd0aa9c64f7135ee6b2c.png" width="600" class="img_ev3q"></div><p>The step are as follows: (i) The question <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> is first embedded into
the same d-dimensional vector space as the chunks were. Let&#x27;s call this vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>;
(ii) k nearest neighbors <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> are searched in the vector index (for some value of k) ; and (iii) the chunks
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> that correspond to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> are retrieved (in the figure above, these
are the chunks in red boxes) and put into the LLM prompt along with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. The
hope is that the chunks whose vector representation were close to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> contain
useful information for the LLM to answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>. In practice there could be more steps to rank those <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span> chunks
and maybe select a fewer number of them to give to the LLM.</p><p>Overall, my reading on standard RAG-U was quite technically deep. That&#x27;s not surprising since
the success of these pipelines depend on two core technical problems:</p><ol><li>How &quot;good&quot; are the embeddings that are inserted into the vector index, i.e., how well does it
capture the relatedness of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to the chunks. This is a core problem in the neural IR.</li><li>How accurate is the vector index in finding top-k nearest neighbors to the vector embedding <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
This is a core database problem.</li></ol><p><em>Important Future Work 1</em>: I believe we should be seeing more exciting work coming up in this space. One
topic is the use of matrices instead of vectors to embed chunks and questions.
This is done in the <a href="https://huggingface.co/colbert-ir/colbertv2.0" target="_blank" rel="noopener noreferrer">ColBERT-style</a> &quot;neural retrieval models&quot;
that are shown to work well on some Q&amp;A benchmarks. Indexing and retrieval of these matrices is an interesting
topic and I have even seen some off-the-shelf tools, e.g., the <a href="https://llamahub.ai/l/llama_packs-ragatouille_retriever?from=llama_packs" target="_blank" rel="noopener noreferrer">RAGatouille package of LlamaIndex</a>, that allows developers to replace the vectors in the
standard RAG-U figure above with matrices. Tons of good future work is possible in this space from improving the accuracy
and efficiency of the vector/matrix indices to the evaluation of RAG-U systems that use these vectors.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="first-envisioned-role-of-knowledge-graphs-in-rag-u-explicitly-linking-chunks">First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks<a href="#first-envisioned-role-of-knowledge-graphs-in-rag-u-explicitly-linking-chunks" class="hash-link" aria-label="Direct link to First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks" title="Direct link to First Envisioned Role of Knowledge Graphs in RAG-U: Explicitly Linking Chunks">​</a></h2><p>One limitation of standard RAG-U is that the chunks are treated as isolated pieces of text. To address this problem,
several posts
that I read (<a href="https://medium.com/neo4j/implementing-advanced-retrieval-rag-strategies-with-neo4j-c968a002c513" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://medium.com/neo4j/using-a-knowledge-graph-to-implement-a-devops-rag-application-b6ba24831b16" target="_blank" rel="noopener noreferrer">2</a>) envision linking these chunks to each other using a KG (or another form of graph). Compared to standard RAG-U,
the design choice for &quot;what additional data&quot; is still document chunks but &quot;how to fetch&quot; is different
and it is a mix of vector index + a KG stored in a GDBMS.
The preprocessing over standard RAG-U (see the preprocessing figure above)
would be enhanced with an additional step as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/kg-enhanced-rag-preprocessing-0258a645794605b4b9469f2756c4a562.png" width="600" class="img_ev3q"></div><p>That is, using some entity extraction mechanism, the chunks would be linked to the entities that
they mention in the KG (assuming the KG contains these entities as nodes). You can think of this linking
as the adding new edges to the KG that relate entities to some chunkIDs that identify the chunks in the vector index.
After the preprocessing step, the standard RAG-U system would be enhanced as follows:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/kg-enhanced-rag-overview-57a9ca61a3e3739118a711237fa28740.png" width="600" class="img_ev3q"></div><p>Similar to standard RAG-U, we have a vector index and additionally a KG, say stored in a GDBMS.
As before <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> is embedded into a vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>Q</mi></msub></mrow><annotation encoding="application/x-tex">v_Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>, whose k nearest neighbors
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> and their corresponding chunks <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
are found in the vector index.
Then, the system extracts additional chunks based on some graph
traversal heuristic. A simple heuristic is to traverse from the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to all entities,
say {<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">e_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>}, that are mentioned in <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">C_1, C_2, ..., C_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.
Then, we can optionally explore the neighborhood of these entities
to extract other entities, say {<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">e_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">e_{m+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span>, ..., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">e_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>}, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">e_{m+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span></span> to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">e_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
are the new entities extracted. Then, we further find other chunks that mention these entities. In the figure
above I&#x27;m simulating this by having a third red box that was not retrieved in the standard RAG-U figure. Now through
another ranking, we can obtain another top-k chunks amongst this new set of chunks and put them into the prompt.</p><p>This vision is interesting and several prior papers also hint at similar related use of
KGs in Q&amp;A applications. The most interesting paper I read that&#x27;s related to this approach was this <a href="https://aclanthology.org/P19-1598.pdf" target="_blank" rel="noopener noreferrer">ACL 2019 paper</a>. This paper pre-dates the current LLMs and is not about RAG. Instead, it
maps the entities mentioned in a question to entities in a KG, and then extracts the subgraph of relations between these
entities from the KG. Then, the relations and entities in this subgraph are used as possible
answers to the question (in some sense, this is also a form of RAG).
The paper&#x27;s approach does not connect the chunks but connects the entities in the question using a KG.
Overall, I think the idea of linking chunks through the entities that they mention is promising
and I want to identify three important future work here that can push this approach forward.</p><p><strong>Important Future Work 2:</strong> This approach assumes that the enterprise already
has a knowledge graph. Although I am a strong believer that enterprises
should invest in the construction of clean enterprise-level KGs with
well defined and consistent vocabularies,
in practice many enterprises do not have readily-available KGs. Therefore the use of this style
of KG-enhanced RAG-U approaches rely on tools that can generate KGs. This is a never ending
quest in academic circles and I&#x27;ll say more about this below (see &quot;Important Future Work 5&quot;).</p><p><em>Important Future Work 3:</em> The graph heuristic I described above to extract further chunks
is only one that can be explored amongst many others. For example, one can map the entities in the question
to nodes in the KG, find shortest paths between them, and retrieve the chunks that mention the nodes/entities
on these paths. These variants need to be systematically evaluated to optimize this approach.</p><p><em>Important Future Work 4:</em> Although variants of this approach, such as  the ACL paper I mentioned have a lot of technical depth
and rigorous evaluations, this approach so far appears only in blog posts which don&#x27;t present an in-depth study. This approach
needs to be subjected to a rigorous evaluation on Q&amp;A benchmarks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="second-envisioned-role-of-knowledge-graphs-in-rag-u-extracting-triples-out-of-chunks">Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks<a href="#second-envisioned-role-of-knowledge-graphs-in-rag-u-extracting-triples-out-of-chunks" class="hash-link" aria-label="Direct link to Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks" title="Direct link to Second Envisioned Role of Knowledge Graphs in RAG-U: Extracting Triples Out of Chunks">​</a></h2><p>In the <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html" target="_blank" rel="noopener noreferrer">LlamaIndex KnowledgeGraphIndex</a> package, there is one more usage of KGs in RAG-U applications.
In this approach, the answer to the &quot;what additional data&quot; question is &quot;triples extracted from the unstructured documents&quot;.
The answer to the &quot;how to fetch&quot; question is to do a retrieval of these triples from a GDBMS.
Here is the preprocessing step:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/triples-based-rag-preprocessing-a78585b0799b8bc8ffb947f170bff914.png" width="600" class="img_ev3q"></div><p>Using some triple extraction, the unstructured document is pre-processed to generate a KG. I will discuss
this step further but overall you can use either a triple extraction model, such as <a href="https://huggingface.co/Babelscape/rebel-large" target="_blank" rel="noopener noreferrer">REBEL</a> or another model, or an LLM directly. Both can be used off-the-shelf. Then, these triples, which form
a KG, are stored in a GDBMS and used in RAG in some form. I&#x27;m giving one example approach below but others
are possible. The approach I will show
is implemented in the examples used in LlamaIndex&#x27;s documentations using <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html" target="_blank" rel="noopener noreferrer">LlamaIndex KnowledgeGraphIndex</a>:</p><div class="img-center"><img loading="lazy" src="/docusaurus/assets/images/triples-based-rag-overview-8034260dd33e3c205ab472f2f292eb2b.png" width="600" class="img_ev3q"></div><p>The triples are stored in a GDBMS. You can use a <a href="https://docs.llamaindex.ai/en/stable/community/integrations/graph_stores.html" target="_blank" rel="noopener noreferrer">LlamaIndex GraphStore</a> for this and Kùzu has an implementation; see the <a href="https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/KuzuGraphDemo.html" target="_blank" rel="noopener noreferrer">KuzuGraphStore demo here</a>. The system extract entities using <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>, using some
entity or keyword extractor. In the LlamaIndex demos, this is done by using an LLM. Specifically,
LLM is prompted with the following <a href="https://github.com/run-llama/llama_index/blob/ce82bd42329b56bca2a6a44e0f690ebedaf1f002/llama_index/prompts/default_prompts.py#L147" target="_blank" rel="noopener noreferrer">prompt</a>: <code>A question is provided below. Given the question, extract up to {max_keywords}
keywords from the text....</code> etc. These keywords are used
to extract triples from the GDBMS by using them in the query sent to the GDBMS as shown in the above figure.
Finally the returned triples are given to the LLM prompt as additional data to help answer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>.</p><p>LlamaIndex offer other ways to extract these triples that are also readily available to use. For example,
you can embed these triples into vectors and use a vector index to fetch them. So although the final
additional data is still triples, how they&#x27;re fetched is through a vector index and not a GDBMS. Other options
are also possible.</p><p>I want to make three points here. First, notice that extracting triples also
provides a means to link the text in the unstructured text, which was a
shortcoming I had highlighted in standard RAG-U. Second, by putting triples into prompts instead of chunks, you are also probably
saving the tokens you are using in your LLM applications. That&#x27;s because triples are like summaries
of the statements in more verbose sentences in chunks.
Third, the success of such RAG applications depends on the quality of the triples
extracted in the pre-processing step, which is the next future work direction I want to highlight:</p><p><em>Important Future Work 5:</em> The success of RAG-U applications that use triples or the KG-enhanced standard
RAG-U applications depend on the availability of a technology that can automatically
extract knowledge graphs from unstructured documents.</p><p>This is a fascinating topic and is a never ending quest in research. Here is
an <a href="https://arxiv.org/pdf/2302.05019.pdf" target="_blank" rel="noopener noreferrer">extensive survey</a> with 358 citations that scared me so I decided to
skip it. But my point is that this has been a never ending research topic. The most recent
work I see here is on using LLMs for this task. I can recommend these two papers here: <a href="https://arxiv.org/abs/2208.11057" target="_blank" rel="noopener noreferrer">1</a> and <a href="https://arxiv.org/pdf/2308.10168.pdf" target="_blank" rel="noopener noreferrer">2</a>.
General conclusions so far are that LLMs are not yet competitive with specialized models
on extracting high quality triples. We&#x27;ll see how far they will go. Surprisingly, a very important question
for which I could not find much to read on is this:</p><p><em>Important Future Work 6:</em> How economical would be the use of LLMs to extract KGs at scale (when they&#x27;re competitive with
specialized methods)? </p><p>So could we ever dream of using LLMs to extract billions of triples from a large corpus of unstructured documents? Probably not
if you&#x27;re using OpenAI APIs, as it would be painfully expensive, or even if you&#x27;re running
your own model, as it would be excruciatingly slow. So I am a bit pessimistic here. My instinct
is that you might be able to generate KGs from unstructured documents using the slightly older
techniques like designing your own models or using extractor-based approaches like
<a href="http://deepdive.stanford.edu/" target="_blank" rel="noopener noreferrer">DeepDive</a><sup id="fnref-3-c9223b"><a href="#fn-3-c9223b" class="footnote-ref">3</a></sup> and <a href="https://tomaarsen.github.io/SpanMarkerNER/" target="_blank" rel="noopener noreferrer">SpanMarker</a><sup id="fnref-4-c9223b"><a href="#fn-4-c9223b" class="footnote-ref">4</a></sup>. I know it&#x27;s not exciting to not use LLMs,
but you&#x27;re likely to extract much higher quality triples and much more cheaply with specialized models.
So I don&#x27;t know who really
thinks it could one day be a good idea to use LLMs to extract triples from large corpuses.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="agents-developing-rag-systems-that-use-both-structured--unstructured-data">Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data<a href="#agents-developing-rag-systems-that-use-both-structured--unstructured-data" class="hash-link" aria-label="Direct link to Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data" title="Direct link to Agents: Developing RAG Systems That Use Both Structured &amp; Unstructured Data">​</a></h2><p>Let me now start wrapping up. In my last post and this one, I covered RAG systems using structured and unstructured data.
There are several tools you can use to develop RAG systems that retrieve data from both
structured records or one that conditionally retrieves from one or the other. <a href="https://python.langchain.com/docs/modules/agents/" target="_blank" rel="noopener noreferrer">LangChain Agents</a>
and <a href="https://docs.llamaindex.ai/en/stable/use_cases/agents.html" target="_blank" rel="noopener noreferrer">LlamaIndex Agents</a>
make it easy to develop such pipelines. You can for example instruct the &quot;Agent&quot; to take one of two actions
conditionally as follows:
&quot;if the question is about counting or aggregations retrieve records from the GDBMS by converting <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>N</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q_{NL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> to a Cypher query;
otherwise follow the RAG-U pipeline to retrieve chunks from documents.&quot; These are essentially
tools to develop a control logic over your LLM applications. It reminds me of the good old days when
there was a crazy hype around MapReduce-like &quot;big data systems&quot; and several initial works, such as <a href="https://dl.acm.org/doi/abs/10.1145/1376616.1376726" target="_blank" rel="noopener noreferrer">Pig Latin</a>
and <a href="https://www.usenix.org/legacy/event/nsdi11/tech/full_papers/Murray.pdf" target="_blank" rel="noopener noreferrer">Ciel</a>, immediately were addressing how to develop libraries/languages
over these systems to implement advanced control flows. Agents, or the recent <a href="https://github.com/langchain-ai/langgraph" target="_blank" rel="noopener noreferrer">LangGraph</a>,
seem like initial answers to the question of &quot;how do you program advanced LLM applications?&quot;</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-words">Final Words<a href="#final-words" class="hash-link" aria-label="Direct link to Final Words" title="Direct link to Final Words">​</a></h2><p>I want to conclude with two final points. First, there are many other applications that can
use LLMs and KGs beyond Q&amp;A. I don&#x27;t have space to cover
them here. Here is a <a href="https://arxiv.org/pdf/2306.08302.pdf" target="_blank" rel="noopener noreferrer">survey paper</a> that attempts to organize
the work in this space. The topics vary from how KGs can be used to train better LLMs to
how LLMs can be used to construct KGs to how one could embed both text and KG triples together as vectors
to better train LLMs.</p><p>Second, I listed 3 possible answers for the &quot;what additional data&quot;
design decision and 3 possible answers for &quot;how to fetch&quot; design decision. I further mentioned different
graph-based heuristics to extract chunks (or triples) once you can link the information in the unstructured
documents to each other through a KG. Many combinations of these design decisions and many other graph heuristics
are not yet explored. So there is quite a lot to explore in this space. The overall impression I was left
with was that we need more technically deep material in the space, which will only come through rigorous evaluations
of these RAG systems on standard benchmarks, as done in SIGIR or ACL publications.
I went through SIGIR 2023 publications and did not find work on a Q&amp;A system that uses LLMs + KGs
similar to the approaches I covered here. I hope to see such papers in 2024.</p><div class="footnotes"><hr><ol><li id="fn-1-c9223b">In this post I&#x27;m only covering approaches
that ultimately use retrieve some unstructured data (or a transformation of it) to put it
into LLM prompts. I am not covering approaches that query a pre-existing KG directly and use the records
in it as additional data into a prompt. See <a href="https://gradientflow.com/boosting-llms-with-external-knowledge-the-case-for-knowledge-graphs/" target="_blank" rel="noopener noreferrer">this post</a> by Ben Lorica
for an example. The 3 point bullet point after the &quot;Knowledge graphs significantly
enhance RAG models&quot; describes such an approach. According to my organization of RAG approaches,
such approaches would fall under RAG using structured data, since KGs are structured records.<a href="#fnref-1-c9223b" class="footnote-backref">↩</a></li><li id="fn-2-c9223b">The term sa-tree stands for &quot;spatial approximation&quot;, which refers to the following fact.
Exact spatial indices like kd-trees are balanced and divide a d-dimensional space into &quot;equal&quot; sub-spaces (not in volume but
in the number of vectors that are contained in the sub-spaces). Instead, sa-trees divide the space approximately and are not
necessarily balanced but sa-trees return exact answers. <a href="#fnref-2-c9223b" class="footnote-backref">↩</a></li><li id="fn-3-c9223b">In DeepDive, you would write extractors for the type
of triples you wanted to extract manually and DeepDive would use them in combination as part of a model
to extract high quality triples. Or you can just default to thinking hard about what you want to extract,
so what type of questions you want to answer in your RAG system, and based on those give example documents
and triples and train a specialized model. <a href="#fnref-3-c9223b" class="footnote-backref">↩</a></li><li id="fn-4-c9223b">SpanMarker is a recent approach for training powerful Named Entity Recognition models and is tightly implemented on top of the Transformers library by Hugging Face. It is based on the <a href="https://arxiv.org/pdf/2109.06067.pdf" target="_blank" rel="noopener noreferrer">PL-Marker paper</a>. The idea is to train a model that can detect NER entities from a large corpus of documents., label them with their types and map these types to the required triples as per your business domain.<a href="#fnref-4-c9223b" class="footnote-backref">↩</a></li></ol></div></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docusaurus/blog/tags/llms">llms</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://join.slack.com/t/kuzudb/shared_invite/zt-1w0thj6s7-0bLaU8Sb~4fDMKJ~oejG_g" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/kuzudb" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@KuzuDB" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://space.bilibili.com/410352593" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bilibili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docusaurus/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/kuzudb/kuzu" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Kùzu Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/docusaurus/assets/js/runtime~main.29273660.js"></script>
<script src="/docusaurus/assets/js/main.c8476cd5.js"></script>
</body>
</html>