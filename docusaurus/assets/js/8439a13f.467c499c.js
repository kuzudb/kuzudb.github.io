"use strict";(self.webpackChunkkuzu_docs=self.webpackChunkkuzu_docs||[]).push([[7131],{3905:(a,e,t)=>{t.d(e,{Zo:()=>l,kt:()=>k});var n=t(7294);function s(a,e,t){return e in a?Object.defineProperty(a,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):a[e]=t,a}function m(a,e){var t=Object.keys(a);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(a);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable}))),t.push.apply(t,n)}return t}function r(a){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?m(Object(t),!0).forEach((function(e){s(a,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(a,Object.getOwnPropertyDescriptors(t)):m(Object(t)).forEach((function(e){Object.defineProperty(a,e,Object.getOwnPropertyDescriptor(t,e))}))}return a}function p(a,e){if(null==a)return{};var t,n,s=function(a,e){if(null==a)return{};var t,n,s={},m=Object.keys(a);for(n=0;n<m.length;n++)t=m[n],e.indexOf(t)>=0||(s[t]=a[t]);return s}(a,e);if(Object.getOwnPropertySymbols){var m=Object.getOwnPropertySymbols(a);for(n=0;n<m.length;n++)t=m[n],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(a,t)&&(s[t]=a[t])}return s}var i=n.createContext({}),o=function(a){var e=n.useContext(i),t=e;return a&&(t="function"==typeof a?a(e):r(r({},e),a)),t},l=function(a){var e=o(a.components);return n.createElement(i.Provider,{value:e},a.children)},h="mdxType",N={inlineCode:"code",wrapper:function(a){var e=a.children;return n.createElement(n.Fragment,{},e)}},c=n.forwardRef((function(a,e){var t=a.components,s=a.mdxType,m=a.originalType,i=a.parentName,l=p(a,["components","mdxType","originalType","parentName"]),h=o(t),c=s,k=h["".concat(i,".").concat(c)]||h[c]||N[c]||m;return t?n.createElement(k,r(r({ref:e},l),{},{components:t})):n.createElement(k,r({ref:e},l))}));function k(a,e){var t=arguments,s=e&&e.mdxType;if("string"==typeof a||s){var m=t.length,r=new Array(m);r[0]=c;var p={};for(var i in e)hasOwnProperty.call(e,i)&&(p[i]=e[i]);p.originalType=a,p[h]="string"==typeof a?a:s,r[1]=p;for(var o=2;o<m;o++)r[o]=t[o];return n.createElement.apply(null,r)}return n.createElement.apply(null,t)}c.displayName="MDXCreateElement"},3475:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>h,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>N});var n=t(7462),s=(t(7294),t(3905)),m=t(6477),r=t(2045),p=t(4287);const i={slug:"llms-graphs-1",authors:["semih"],tags:["use-case"]},o="RAG Using Structured Data: Overview & Important Questions",l={permalink:"/docusaurus/blog/llms-graphs-1",source:"@site/blog/2024-01-04-llms-graphs-part-1/index.md",title:"RAG Using Structured Data: Overview & Important Questions",description:"During the holiday season, I did some reading on",date:"2024-01-04T00:00:00.000Z",formattedDate:"January 4, 2024",tags:[{label:"use-case",permalink:"/docusaurus/blog/tags/use-case"}],readingTime:25.13,hasTruncateMarker:!1,authors:[{name:"Semih Saliho\u011flu",title:"CEO of K\xf9zu Inc & Associate Prof. at UWaterloo",url:"https://cs.uwaterloo.ca/~ssalihog/",imageURL:"https://kuzudb.com/img/blog/semih.jpg",key:"semih"}],frontMatter:{slug:"llms-graphs-1",authors:["semih"],tags:["use-case"]},nextItem:{title:"K\xf9zu 0.1.0 Release",permalink:"/docusaurus/blog/kuzu-0.1.0-release"}},h={authorsImageUrls:[void 0]},N=[{value:"Killer App: Retrieval Augmented Generation",id:"killer-app-retrieval-augmented-generation",level:2},{value:"A note on the term RAG",id:"a-note-on-the-term-rag",level:3},{value:"Summary of this post",id:"summary-of-this-post",level:3},{value:"RAG Using Structured Data: Text-to-High-level-Query",id:"rag-using-structured-data-text-to-high-level-query",level:2},{value:"Overview",id:"overview",level:3},{value:"Simplicity of Developing RAG Systems: LangChain and LlamaIndex",id:"simplicity-of-developing-rag-systems-langchain-and-llamaindex",level:3},{value:"How Good Are LLMs in Generating High-Level Queries?",id:"how-good-are-llms-in-generating-high-level-queries",level:3},{value:"data.world Paper and Some Interesting Questions",id:"dataworld-paper-and-some-interesting-questions",level:2},{value:"Final Words",id:"final-words",level:2}],c={toc:N},k="wrapper";function d(a){let{components:e,...t}=a;return(0,s.kt)(k,(0,n.Z)({},c,t,{components:e,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"During the holiday season, I did some reading on\nLLMs and specifically on the techniques that use LLMs together with graph databases and knowledge graphs.\nIf you are new to the area like me, the amount of activity on this topic on social\nmedia as well as in research publications may have intimidated you.\nIf so, you're exactly my target audience for this new blog post series I am starting.\nMy goals are two-fold: "),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},"Overview the area"),": I want to present what I learned with a simple and consistent terminology and at\na more technical depth than you might find in other blog posts. I am aiming a depth similar to what I aim when preparing\na lecture. I will link to many quality and technically satisfying pieces of content (mainly papers since the area is very researchy)."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},"Overview important future work"),": I want to cover several important future works in the space. I don't\nnecessarily mean work for research contributions but also simple approaches to experiment with if you are\nbuilding question answering (Q&A) applications using LLMs and graph technology.")),(0,s.kt)("h2",{id:"killer-app-retrieval-augmented-generation"},"Killer App: Retrieval Augmented Generation"),(0,s.kt)("p",null,"Let's review the killer application of LLMs in enterprises.\nThe application is ultimately Q&A over private enterprise data. Think of a chatbot to which you\ncan ask natural language questions (",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),'), such as: "Who is our top paying customer from Waterloo?",\nor "What are data privacy regulations in Canada we need to comply with?"\nand get back natural language answers (',(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"A"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"A_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"A"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),").\nLLMs, out of the box, cannot answer these questions because they have a ",(0,s.kt)("em",{parentName:"p"},"knowledge gap"),".\nFor example, LLMs never had any access to your sales records when they were trained.\nTherefore, they need to retrieve or be provided with\nextra information from private data sources of the enterprise."),(0,s.kt)("h3",{id:"a-note-on-the-term-rag"},"A note on the term RAG"),(0,s.kt)("p",null,"There seems to be tremendous interest in building systems that combine a traditional\ninformation retrieval component, e.g., one that looks up some documents from\nan index, with a natural language generator component, such as an LLM. The term for such systems is\n",(0,s.kt)("em",{parentName:"p"},"Retrieval Augmented Generation")," (RAG).\nThe term is coined in ",(0,s.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2005.11401.pdf"},"this paper"),' to refer\nto the method of fine-tuning an LLM with additional information, i.e.,\nusing this additional data to train a new variant of the LLM.\nThe original usage form in the paper is "RAG models". Nowadays it is used in a variety of ways,\nsuch as, "RAG system", "RAG-based system", "RAG does X", or\n"Building RAG with Y". RAG often does not refer to fine-tuning LLMs any more. Instead, it\nrefers to providing LLMs with private data along with the question to fix the knowledge gap.\nEven systems that simply use an LLM to convert a\n',(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),' to SQL or Cypher query and simply return the results of the query\nare called "RAG systems" in some documentations. I will use the term in this broader sense.'),(0,s.kt)("p",null,"You can build RAG-based Q&A systems by using structured and/or unstructured\ndata. The high-level views of these systems look like this:"),(0,s.kt)("div",{class:"img-center"},(0,s.kt)("img",{src:m.Z,width:"600"})),(0,s.kt)("h3",{id:"summary-of-this-post"},"Summary of this post"),(0,s.kt)("p",null,"This post covers RAG using structured data. Then, in a follow up post, I will cover RAG using unstructured data, where\nI will also mention a few ways people are building RAG-based Q&A\xa0systems that use both structured and unstructured data."),(0,s.kt)("admonition",{title:"TL;DR: The key takeaways from this post are:",type:"tip"},(0,s.kt)("ul",{parentName:"admonition"},(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"RAG overview"),": RAG is a technique to fill the knowledge gap of LLMs using private data. RAG systems\nuse  private structured records stored in a database and/or unstructured data in text files. "),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Impressive simplicity and effectiveness of developing a natural language interface over your database using LLMs"),": In the pre-LLM era, the amount of engineering effort\nto develop a pipeline that delivered a natural language interface over your database was ",(0,s.kt)("em",{parentName:"li"},"immense"),". The\nhard problem was to teach a model to ",(0,s.kt)("em",{parentName:"li"},"speak"),' SQL, Cypher, or SPARQL.\nThis contrasts sharply with the simplicity of developing similar pipelines now because LLMs already "speak" these languages.\nThe hard task now is for ',(0,s.kt)("em",{parentName:"li"},"developers to learn how to prompt LLMs")," to get correct database queries. Furthermore, there is\nevidence that LLMs, if prompted correctly, will generate a decent proportion of queries with impressive accuracy.  "),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Lack of work that studies LLMs' ability to generate Cypher or SPARQL:")," Most technically-deep work on understanding\nLLMs' ability to generate accurate high-level query languages is on SQL. We need more\nwork understanding the behavior of LLMs on the query languages of GDBMSs (like Cypher or SPARQL), specifically on recursive and union-of-join queries."),(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("strong",{parentName:"li"},"Studying the effects of data modeling (normalization, views, graph modeling) on the accuracy of LLM-generated queries is important:"),"\nMany people are studying heuristics for prompting LLMs to increase their efficiency focusing on the syntax and the structure of providing\nthe schema and selection of examples in the prompt. An important and under-studied\nproblem is the effects of data modeling choices on the accuracy of the queries generated by LLMs. I point to ",(0,s.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2311.07509.pdf"},"one interesting paper")," in this space and raise several questions related to\nnormalizations and use of views in relational modeling and comparisons with graph modeling approaches. "))),(0,s.kt)("h2",{id:"rag-using-structured-data-text-to-high-level-query"},"RAG Using Structured Data: Text-to-High-level-Query"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},'Note: If you are familiar with how to develop RAG systems with LangChain and LlamaIndex, you can directly skip\nto the "',(0,s.kt)("a",{parentName:"em",href:"#how-good-are-llms-in-generating-high-level-queries"},"How Good are LLMs in Generating High-level Queries"),'" part that\nreflects on the reading I did on RAG using structured data.')),(0,s.kt)("h3",{id:"overview"},"Overview"),(0,s.kt)("p",null,"Many blog posts and several papers concern Q&A systems that simply convert\n",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," to a high-level query languge, such as SQL, Cypher, or SPARQL, using an LLM.\nThe figure below describes the overall approach:"),(0,s.kt)("div",{class:"img-center"},(0,s.kt)("img",{src:r.Z,width:"600"})),(0,s.kt)("p",null,(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),', the schema of a database, and optionally\nsome example natural language question and high-level query examples, are given\nto the LLM as a prompt.\nThe terms "no shot", "one shot", or "few shot" refer to the number of examples provided\nin the prompt. Depending on the underlying database, the schema may contain\ncolumns of relational tables and their descriptions, or labels of nodes and edges\nof a graph database. Using ',(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),", the database schema, and optionally\nsome examples, the LLM generates\na database query, such as SQL or Cypher. The system runs this query against the\nDBMS and returns back the query result or using the LLM again, converts\nthe query result back to a natural language answer ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"A"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"A_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"A"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),". "),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Let us pause here to appreciate one thing:")," For many decades, the database community has studied the problem\nof converting ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),' to SQL (aka "text-to-SQL"). Here is a good recent ',(0,s.kt)("a",{parentName:"p",href:"https://link.springer.com/article/10.1007/s00778-022-00776-8"},"survey paper"),"\nthat covers only the deep network-based approaches and ",(0,s.kt)("a",{parentName:"p",href:"https://www.nowpublishers.com/article/Details/DBS-078"},"a more extensive survey/book"),"\non the broader topic of natural language interfaces to databases.\nNeither of these surveys cover any work that directly uses LLMs such as GPT models,\nwhich are quite recent developments. Take any of the work covered in these surveys and\nyou'll find an approach that requires significant engineering to build the pipeline shown in the above figure.\nThere exist several pre-LLM text-to-SQL systems (e.g., ",(0,s.kt)("a",{parentName:"p",href:"https://www.vldb.org/pvldb/vol9/p1209-saha.pdf"},"ATHENA"),"\nor ",(0,s.kt)("a",{parentName:"p",href:"https://download.hrz.tu-darmstadt.de/pub/FB20/Dekanat/Publikationen/UKP/76500354.pdf"},"BELA"),").\nFor example, most of the pre-LLM approaches that use deep learning require\nhard work ",(0,s.kt)("em",{parentName:"p"},'to teach a model how to "speak" SQL')," using large\ncorpora of tables and (question, query) examples, such as ",(0,s.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/1709.00103"},"WikiSQL")," or ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/taoyds/spider"},"Spider"),".\nPeople had to solve and glue-together solutions to many technical problems, such as parsing the question,\nentity detection, synonym finding, string similarity, among others.\nPost-LLM approaches require ",(0,s.kt)("em",{parentName:"p"},"none")," of these efforts because LLMs, such as GPT-4, already speak SQL, Cypher, and SPARQL out of the box, having been exposed to them in their pretraining.\nNowadays, the hard problem now is for developers ",(0,s.kt)("em",{parentName:"p"},"to learn how to prompt LLMs")," so that\nLLMs generate correct queries. I'll say more about this problem. In contrast, building the above pipeline requires much less effort as\nI'll show next."),(0,s.kt)("h3",{id:"simplicity-of-developing-rag-systems-langchain-and-llamaindex"},"Simplicity of Developing RAG Systems: LangChain and LlamaIndex"),(0,s.kt)("p",null,"If you have been following the developments in the LLM space, you will not be surprised to hear that nowadays people build\nQ&A systems that convert ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," to a high-level query language using two common tools:\n(i) ",(0,s.kt)("a",{parentName:"p",href:"https://www.langchain.com/"},"LangChain"),"; and (ii) ",(0,s.kt)("a",{parentName:"p",href:"https://www.llamaindex.ai/"},"LlamaIndex"),".\nThe same tools also integrate with the underlying storage system to load and retrieve your data. To make this more concrete, let me review the ",(0,s.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/use_cases/graph/graph_kuzu_qa"},"K\xf9zu-LangChain integration"),", similar to the integrations found in other GDBMSs. You as a programmer have very little to do: you prepare your K\xf9zu\ndatabase ",(0,s.kt)("inlineCode",{parentName:"p"},"db")," and load your data into it, wrap it around a ",(0,s.kt)("inlineCode",{parentName:"p"},"KuzuGraph")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"KuzuQAChain")," objects in Python and you have\na text-to-Cypher pipeline:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'import kuzu\nfrom langchain.chains import KuzuQAChain\nfrom langchain_community.chat_models import ChatOpenAI\nfrom langchain_community.graphs import KuzuGraph\n\ndb = kuzu.Database("test_db")\n... // create your graph if needed\ngraph = KuzuGraph(db)\nchain = KuzuQAChain.from_llm(ChatOpenAI(temperature=0), graph=graph, verbose=True)\nchain.run("Who played in The Godfather: Part II?")\n')),(0,s.kt)("p",null,"I am following the example application in this ",(0,s.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/use_cases/graph/graph_kuzu_qa"},"documentation"),",\nwhich uses a database of movies, actors, and directors. "),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"Output:\n> Entering new  chain...\nGenerated Cypher:\nMATCH (p:Person)-[:ActedIn]->(m:Movie {name: 'The Godfather: Part II'}) RETURN p.name\nFull Context:\n[{'p.name': 'Al Pacino'}, {'p.name': 'Robert De Niro'}]\n\n> Finished chain.\n\n'Al Pacino and Robert De Niro both played in The Godfather: Part II.'\n")),(0,s.kt)("p",null,'The "chain" first generated a Cypher query using ',(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),".\nBehind the curtain, i.e., inside the KuzuQAChain code,\na GPT model was given the following prompt:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},"Generate Cypher statement to query a graph database.\nInstructions:\nUse only the provided relationship types and properties in the schema.\nDo not use any other relationship types or properties that are not provided.\n\nSchema:\nNode properties: [{'properties': [('name', 'STRING')], 'label': 'Movie'}, {'properties': [('name', 'STRING'), ('birthDate', 'STRING')], 'label': 'Person'}]\nRelationships properties: [{'properties': [], 'label': 'ActedIn'}]\nRelationships: ['(:Person)-[:ActedIn]->(:Movie)']\n\nNote: Do not include any explanations or apologies in your responses.\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\nDo not include any text except the generated Cypher statement.\n\nThe question is:\nWho played in The Godfather: Part II?\n")),(0,s.kt)("p",null,"Indeed, if you copy this prompt and paste it in ",(0,s.kt)("a",{parentName:"p",href:"https://chat.openai.com/"},"chatGPT's browser interface"),",\nyou will get the same or very similar Cypher query. The important point is: that's all\nthe coding you have to do to build a natural language interface that can query your database.\nYou ultimately construct a string prompt that contains ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),", some\ninstructions, and schema of the database, and the LLM will generate a query for you.\nThe ",(0,s.kt)("inlineCode",{parentName:"p"},"KuzuGraph")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"KuzuQAChain")," are simple wrappers to do just that.\nIf you want to play around with how well this works on other datasets,\nwe have this pipeline implemented in K\xf9zu's browser frontend ",(0,s.kt)("a",{parentName:"p",href:"https://kuzudb.com/docusaurus/kuzuexplorer/"},"K\xf9zuExplorer"),". "),(0,s.kt)("p",null,'That is, for any database you have in K\xf9zu, you get a natural language interface over it in\nK\xf9zuExplorer (just click the "robot icon" on the left panel).\nYou can develop similar pipelines with other GDBMSs using similar interfaces (',(0,s.kt)("em",{parentName:"p"},"though I recommend using K\xf9zu as it will be the\nsimplest to get started")," \ud83d\ude09: ",(0,s.kt)("em",{parentName:"p"},"Unlike other GDBMSs, K\xf9zu is embeddable and requires no server set up"),").\nIf you instead want to build Q&A systems over your RDBMSs, you can use\nLangChain's ",(0,s.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/use_cases/qa_structured/sql#case-2-text-to-sql-query-and-execution"},"SQLDatabaseChain")," and\n",(0,s.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/use_cases/qa_structured/sql#case-3-sql-agents"},"SQLAgent")," or\nLlamaIndex's ",(0,s.kt)("a",{parentName:"p",href:"https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html#part-1-text-to-sql-query-engine"},"NLSQLTableQueryEngine"),'. The level of simplicity is similar to the example I presented. In practice, it is unlikely that your chatbot or search engine will be as simple\nas the above example where the application interacts with the LLM only once. If you want\nto interact with the LLM multiple times and conditionally take one action over another action etc.,\nLangChain and LlamaIndex also provide ways to do that through their "Agents" (see ',(0,s.kt)("a",{parentName:"p",href:"https://python.langchain.com/docs/modules/agents/"},"LangChain Agents")," and ",(0,s.kt)("a",{parentName:"p",href:"https://docs.llamaindex.ai/en/stable/use_cases/agents.html"},"Llama Index Agents"),")."),(0,s.kt)("h3",{id:"how-good-are-llms-in-generating-high-level-queries"},"How Good Are LLMs in Generating High-Level Queries?"),(0,s.kt)("p",null,"Although building a text-to-high-level-query-language pipeline is now very simple with LLMs,\nsimplicity ",(0,s.kt)("strong",{parentName:"p"},"does not")," mean quality. Indeed, people building these systems are now faced with the following two important questions: "),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},"How accurate are the high-level queries that LLMs generate?")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},"How, e.g., through what types of prompts or data modeling, can we increase the accuracy of the\nqueries generated by LLMs?"))),(0,s.kt)("p",null,"Here are several papers on this that I suggest reading:"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2303.13547.pdf"},"A comprehensive evaluation of ChatGPT\u2019s zero-shot Text-to-SQL capability"))," from Tsinghua University and University of Illinois at Chicago. "),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2204.00498.pdf"},"Evaluating the Text-to-SQL Capabilities of Large Language Models"))," from researchers from Cambridge and universities and institutes from Montr\xe9al."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2308.15363.pdf"},"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation"))," from Alibaba Group."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2305.12586.pdf"},"Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies"))," from Yale, Columbia, and Allen Institute for AI."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2305.11853.pdf"},"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings"))," from Ohio State"),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://arxiv.org/pdf/2311.07509.pdf"},"A Benchmark to Understand the Role of Knowledge Graphs on LLM's Accuracy for Q&A on Enterprise SQL Databases"))," from data.world.")),(0,s.kt)("p",null,"These papers are either entirely or ",(0,s.kt)("em",{parentName:"p"},"almost")," entirely evaluation-only papers that experiment with very detailed approaches of prompting LLMs\nto generate SQL queries. First, let me say that the general message these\npapers give (maybe except the last one) is that LLMs are pretty good. With right prompting (or even with basic prompting)\nthey do very well on these benchmarks. I see accuracy rates over 85% on the Spider benchmark in several papers. These are clearly\nbetter numbers than what pre-LLM state-of-the-art systems achieved. This should be impressive to many."),(0,s.kt)("p",null,'Second, the set of techniques are too detailed to cover here but some example heuristics\nthese papers experiment with include the following: (i) the syntax used for providing the schema\n(apparently putting "the pound sign ',(0,s.kt)("inlineCode",{parentName:"p"},"#")," to differentiate prompt from response in examples yields impressive performance gains\" \ud83d\ude00 go figure); (ii)\nthe number and selection of example (question, SQL) pairs, e.g., apparently there is a sweet spot in the number\nof examples to provide; or (iii) the effects of standardizing the text in the prompt, e.g., indenting and using all lower case letters consistently\n(apparently has minor but some effect). Yes, as interesting and important it is to learn how to use LLMs better, I still\ncan't escape the following thought before going to bed: somewhere out there, some advisor might be torturing some graduate student\nto check if the magical box produces better SQL with a pound sign vs double slashes!"),(0,s.kt)("p",null,"Most work I found is on generating SQL.\nIn contrast, I found no papers that do similar prompting study for query languages\nof GDBMS though I ran into two papers that are providing benchmarks for query languages of GDBMSs:\n(i) ",(0,s.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2309.16248"},"SPARQL"),"; and (ii) ",(0,s.kt)("a",{parentName:"p",href:"https://dl.acm.org/doi/pdf/10.1145/3511808.3557703"},"Cypher"),").\nSo a low-hanging fruit future work is the following:"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Important Future Work 1: Similar prompting studies for query languages of graph DBMSs with a focus on recursive and unions of joins queries."),":\nIn contrast to SQL queries, here, one should study various recursive queries that the query languages of GDBMSs are particularly good\nat and union-of-join queries which are asked by omitting labels in the query languages of GDBMSs.\nFor example if you want to ask all connections between\nyour ",(0,s.kt)("inlineCode",{parentName:"p"},"User")," nodes and User can have many relationships, such as ",(0,s.kt)("inlineCode",{parentName:"p"},"Follows"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"SentMoneyTo"),", or ",(0,s.kt)("inlineCode",{parentName:"p"},"SameFamily"),",\nyou would have to write 3 possible join queries in SQL and union them. Instead, you can write this query\nwith a very simple syntax in Cypher as\n",(0,s.kt)("inlineCode",{parentName:"p"},"MATCH (a:User)-[e]->(b:User)"),", where the omissions of the label on the relationship ",(0,s.kt)("inlineCode",{parentName:"p"},"e")," indicates searching over\nall possible joins.",(0,s.kt)("sup",{parentName:"p",id:"fnref-1-a733ad"},(0,s.kt)("a",{parentName:"sup",href:"#fn-1-a733ad",className:"footnote-ref"},"1"))," "),(0,s.kt)("p",null,"As a side note: In the context of any query language, including SQL, questions that require sub-queries are of particular\ninterest as they are generally harder to write. Some of the papers I read had sections analyzing the performance of\nLLMs on nested queries but the focus was not on these. In prior literature there are papers written solely on text-to-SQL generation for\nnested queries (e.g., see ",(0,s.kt)("a",{parentName:"p",href:"https://www.vldb.org/pvldb/vol13/p2747-sen.pdf"},"the ATHENA++ paper"),"). I am certain someone\nsomewhere is already focusing solely on nested queries and that's a good idea."),(0,s.kt)("h2",{id:"dataworld-paper-and-some-interesting-questions"},"data.world Paper and Some Interesting Questions"),(0,s.kt)("p",null,"In the remainder of the post I want to review ",(0,s.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/2311.07509.pdf"},"the benchmark paper")," from ",(0,s.kt)("inlineCode",{parentName:"p"},"data.world")," that focuses on text-to-SQL using LLMs. Unlike other papers out there that\nstudy the effects of different prompting heuristics, this paper studies the ",(0,s.kt)("em",{parentName:"p"},"effects of data modeling\non the accuracy of SQL queries generated by LLMs"),", which is closely related to GDBMSs. "),(0,s.kt)("p",null,"Specifically, this paper is an evaluation of the performance of GPT-4 in generating SQL using no examples, i.e., zero-shot,\nwith basic prompting over a standardized insurance database schema\ncalled The ",(0,s.kt)("a",{parentName:"p",href:"https://www.omg.org/spec/PC/1.0/About-PC"},"OMG Property and Casualty Data Model"),".\nSee Figure 1 in the paper (omitted here) for the conceptual schema, which consists of classes such as\nPolicy, Account, Claims, Insurable Object, among others, and their relationships.\nThe paper has a benchmark of 43 natural language questions and compares 2 approaches to generate the SQL query.\nThe below figure shows an overview of these approaches for reference:"),(0,s.kt)("div",{class:"img-center"},(0,s.kt)("img",{src:p.Z,width:"600"})),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Direct SQL Generation: In this approach, ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," and the relational schema of the OMG database is given\nto GPT-4. The schema is given in terms of ",(0,s.kt)("inlineCode",{parentName:"li"},"CREATE TABLE")," statements, such as:",(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE Claim(\nClaim_Identifier     int  NOT NULL,\nCatastrophe_Identifier int  NULL,\n...\nClaim_Open_Date      datetime  NULL ,\n ...\n PRIMARY KEY (Claim_Identifier ASC),\n FOREIGN KEY (Catastrophe_Identifier) REFERENCES Catastrophe(Catastrophe_Identifier),\n...)\n")),"The full schema statements can be found ",(0,s.kt)("a",{parentName:"li",href:"https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/DDL/ACME_small.ddl"},"here"),".\nGPT-4 is asked to generate a SQL query ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"SQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," to answer ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),".\nCopy-pasted from the paper, these prompts look as follows:",(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"Given the database described by the following DDL:\n<INSERT CREATE STATEMENTS FOR SCHEMA>\nWrite a SQL query that answers the following question. Do not explain the query. return just the query, so it can be run\nverbatim from your response.\nHere\u2019s the question:\n<INSERT QUESTION>\n"))),(0,s.kt)("li",{parentName:"ol"},"Indirect SQL Generation via Graph Modeling/SPARQL: In this approach, instead of the relational schema of the database, the same\ndatabase is modeled as an ",(0,s.kt)("em",{parentName:"li"},(0,s.kt)("a",{parentName:"em",href:"https://www.w3.org/OWL/"},"OWL ontology"))," (OWL is short for Web Ontology Language).\nOntology is another term for schema when modeling data as graph as classes and relationships between them. OWL is a W3C standard\nand part of the RDF technology stack so OWL ontologies are expressed as a set RDF triples, such as:",(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},'...\nin:Claim rdf:type owl:Class ;\n      rdfs:isDefinedBy <http://data.world/schema/insurance/> ;\n      rdfs:label "Claim" .\nin:claimOpenDate rdf:type owl:DatatypeProperty ;\n              rdfs:domain in:Claim ;\n              rdfs:range xsd:dateTime ;\n              rdfs:isDefinedBy <http://data.world/schema/insurance/> ;\n              rdfs:label "Claim Open Date" .\nin:hasCatastrophe rdf:type owl:ObjectProperty ;\n               rdfs:domain in:Claim ;\n               rdfs:range in:Catastrophe ;\n               rdfs:isDefinedBy <http://data.world/schema/insurance/> ;\n               rdfs:label "has catastrophe" .\n...\n')),"The full ontology can be found ",(0,s.kt)("a",{parentName:"li",href:"https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/ontology/insurance.ttl"},"here"),".\nGPT-4 is then asked to generate a SPARQL query ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"P"),(0,s.kt)("mi",{parentName:"mrow"},"A"),(0,s.kt)("mi",{parentName:"mrow"},"R"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SPARQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.13889em"}},"SP"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"A"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"RQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"})))))))))),", instead of SQL, for the same ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"})))))))))),". The full prompt, again copy-pasted\nfrom the paper with some simplifications, looks like this:",(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"Given the OWL model described in the following TTL file:\n<INSERT OWL ontology as triples>\nWrite a SPARQL query that answers the question. Do not explain the query. return just the query, so it can be run verbatim from your response.\nHere\u2019s the question:\n<INSERT QUESTION>\n")),"As a last step, the authors have a direct mapping from ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"P"),(0,s.kt)("mi",{parentName:"mrow"},"A"),(0,s.kt)("mi",{parentName:"mrow"},"R"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SPARQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.13889em"}},"SP"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"A"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"RQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," to a SQL query ",(0,s.kt)("span",{parentName:"li",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"SQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"})))))))))),". This is a quite straigh-forward step\nas the modeling as an ontology vs relational schema have direct translations from classes and properties to tables and columns.")),(0,s.kt)("p",null,"An interesting comparison. There is some intuition for why one would be interested in the effectiveness of\nquery generation through an ontology because one of the well-known\npre-LLM text-to-SQL papers ",(0,s.kt)("a",{parentName:"p",href:"https://www.vldb.org/pvldb/vol9/p1209-saha.pdf"},"ATHENA")," did something similar.\nInstead of SPARQL they had another query language over an ontology called Ontology Query Language, which\nwas then mapped to SQL. "),(0,s.kt)("p",null,"The results are even more interesting. The authors categorize their 43 questions into\n4 quadrants based on 2 dimensions: "),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"Low vs high ",(0,s.kt)("strong",{parentName:"li"},"question")," complexity: Questions that require only simple projections\nare low complexity. Those that require aggregations or math functions are high complexity."),(0,s.kt)("li",{parentName:"ul"},"Low vs high ",(0,s.kt)("strong",{parentName:"li"},"schema")," complexity: Questions whose SQL queries require up to 4 tables are low schema complexity. Those that\nrequire 5 or more joins are high schema complexity. ")),(0,s.kt)("p",null,'The accuracy results are shown below. Accuracy here is "execution accuracy" meaning that  only the answers of the queries\nare checked against the ground truth answer. That is, even if the SQL query GPT-4 generated was actually not correct\nbut by luck it computed the correct answers the paper takes it as correct (apparently happens very rarely in this study).'),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null},"Overall: 16.7% vs 54.2%"),(0,s.kt)("th",{parentName:"tr",align:null},"Low Schema Complexity"),(0,s.kt)("th",{parentName:"tr",align:null},"High Schema Complexity"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("b",null,"Low Question Complexity")),(0,s.kt)("td",{parentName:"tr",align:null},"37.4% vs 66.9%"),(0,s.kt)("td",{parentName:"tr",align:null},"0% vs 38.7%")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},(0,s.kt)("b",null,"High Question Complexity")),(0,s.kt)("td",{parentName:"tr",align:null},"25.5% vs 71.1%"),(0,s.kt)("td",{parentName:"tr",align:null},"0% vs 35.7%")))),(0,s.kt)("p",null,"Overall, the indirect SQL generation method through SPARQL is much more effective in this zero-shot setting.\nNot surprisingly, questions that require 5 or more joins are harder regardless of the\nmethod used and direct SQL cannot get any of those questions right. These are interesting\nresults for an initial study on the effects of data modeling on LLMs' accuracy on generating database queries.\nThese results should give many researchers and practitioners ideas about how to replicate\nand validate/invalidate similar results under different settings, e.g., with few-shot\nexamples and under different databases."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"That said, one should ask, why?")," In fact, we should all be suspicious that merely modeling the\nsame set of records with a different abstraction should have any visible effects. After all, by modeling\nthe same records differently, one does not obtain or lose information. So if and when LLMs are smart enough,\nthey shouldn't care how the data was modeled. But for now, if a pound sign can make a difference,\nwe should not be surprised modeling choices can have large impacts. As such, it is healthy to be suspicious\nand ask why. These motivate a few important questions I think are worth studying. My premise\nis that somehow if the differences are this large, it must be that the task for GPT-4 got simpler when\nasked to generate a SPARQL query. I can hypothesize about a few possible reasons for this: "),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},(0,s.kt)("p",{parentName:"li"},(0,s.kt)("em",{parentName:"p"},"Some queries require fewer tokens to write in SPARQL"),": One difference the query languages\nof GDBMSs often have is that certain equality conditions are implicit in the syntax, which\nmeans their ",(0,s.kt)("inlineCode",{parentName:"p"},"WHERE")," clauses are simpler for some queries. For example if you wanted to return\nthe names of the Catastrophe that Claim with ID Claim1 has, in SPARQL you can write it as:"),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"SELECT ?name\nWHERE { <in:Claim1> in:hasCatastrophe ?catastrophe,\n        ?catastophe in:catastropheName ?name}\n")),(0,s.kt)("p",{parentName:"li"},"In SQL you would write:"),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"SELECT Catastrophe_Name\nFROM Claim, Catastrophe\nWHERE Claim.Catastrophe_Identifier = Catastrophe.Catastrophe_Identifier AND\n      Claim.Claim_Identifier = Claim1\n")),(0,s.kt)("p",{parentName:"li"},"Note that the ",(0,s.kt)("inlineCode",{parentName:"p"},"Claim.Claim_Identifier = Claim1")," equality condition is implicit in the ",(0,s.kt)("inlineCode",{parentName:"p"},"<in:Claim1> in:hasCatastrophe ?catastrophe")," triple\nand the ",(0,s.kt)("inlineCode",{parentName:"p"},"Claim.Catastrophe_Identifier = Catastrophe.Catastrophe_Identifier")," condition is implicit in the fact that ",(0,s.kt)("inlineCode",{parentName:"p"},"?catastrophe")," appears\nboth in the first and second triples in the SPARQL query. Such implicit equality conditions are common in the languages of\ngraph query languages especially when expressing joins. For example in Cypher you can omit all join conditions in WHERE clauses as long\nas those joins have been pre-defined to the system as relationships. Instead you join records through the ",(0,s.kt)("inlineCode",{parentName:"p"},"(a)-[e]->(b)")," syntax.\nIt's unclear how much this could matter but it is an immediate advantage of SPARQL that can explain why complex join queries are easier to generate\nin SPARQL than SQL.  "),(0,s.kt)("p",{parentName:"li"},(0,s.kt)("strong",{parentName:"p"},"Side note"),": On the flip side, SPARQL can be more verbose in projections. For example, if you wanted to return the number, open and close\ndates of every claim, you'd write the following SQL query:"),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"SELECT Claim_Number, Claim_Open_Date, Claim_Close_Date\nFROM Claim\n")),(0,s.kt)("p",{parentName:"li"},"In SPARQL, you'd have to write both the names of the property you want to project and give it an additional variable as follows:"),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"SELECT ?number, ?open_date, ?close_date\nWHERE { ?claim in:claimNumber ?number,\n        ?claim in:claimOpenDate ?open_date,\n        ?claim in:claimCloseDate ?close_date\n")))),(0,s.kt)("ol",{start:2},(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("em",{parentName:"li"},"Graph modeling gives explicit names to foreign keys:")," There is a reason that database courses teach database modeling to students\nusing graph-based models, such as Entity-Relationship or UML models. First, humans think of the world\nas objects/entities and their relationships. In some sense, these are higher-level models where relationships\nbetween objects are denoted explicitly with explicit names (instead of as less explicit foreign key constraints).\nFor example, the implicit connection between Claims and\nCatastrophes through the ",(0,s.kt)("inlineCode",{parentName:"li"},"FOREIGN KEY (Catastrophe_Identifier) REFERENCES Catastrophe(Catastrophe_Identifier)"),"\nconstraint was given an explicit English name: ",(0,s.kt)("inlineCode",{parentName:"li"},"hasCatastrophe")," in the ontology. This explicitness may make\nit easier for LLMs to understand the schema and generate SPARQL queries.")),(0,s.kt)("p",null,"Both of these are qualitative hypotheses. however, there is a more immediate\nreason the authors of this paper may have obtained such major differences between the two approaches they tried.\nIntentionally or unintentionally, their ontology is simplified significantly compared to the relational schema they have.\nFor example, the Claim relation has ",(0,s.kt)("inlineCode",{parentName:"p"},"Claim_Reopen_Date")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"Claim_Status_Code")," properties which are removed from the ontology.\nMany such properties from the relations seem to have been removed, and the ontology overall looks simpler.\nThere are also several differences between the ontology and the relational schema that are confusing. For example\nthe ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/ontology/insurance.ttl"},"ontology"),"\nhas a class ",(0,s.kt)("inlineCode",{parentName:"p"},"Agent")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"Policy")," objects are ",(0,s.kt)("inlineCode",{parentName:"p"},"in:soldByAgent")," by some Agent objects (see lines 20 and 92). I cannot\nsee corresponding relations or columns in the ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/datadotworld/cwd-benchmark-data/blob/main/ACME_Insurance/DDL/ACME_small.ddl"},"relational schema"),". Unless I am missing something about how the prompts were given,\nthese are also likely to have important effects on the results and someone should fix and obtain new results\nin a more fair comparison."),(0,s.kt)("p",null,"Let me next raise several high-level questions that I think are important:"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Important Future Work 2: Rules of thumbs in data modeling to make LLM-generated queries more accurate."),"\nI think the higher-level question of studying the effects of data modeling in more depth is a very good direction.\nAs LLMs get smarter, I would expect that the presence/absence of a pound sign or the style of English\nshould matter less. These look more like syntactic differences that can be automatically detected over time.\nModeling choices are more fundamental and relate to the clarity and understandibility of the records that will be queried by the LLM.\nSo identifying some rules of thumb here looks like the promising path forward. Let me list a few immediate questions one can study:"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Important Future Work 2.1: Effects of normalization/denormalization.")," If the shortcoming of GPT-4 is\ngenerating queries with many joins, one way to solve this is to denormalize the relations into fewer\ntables and study its effects. Again, I'm thinking of same records just modeled differently with fewer\ntables. What happens if we reduce all data into a single table with dozens of columns and many value repetitions?\nNow all possible joins would have been performed so we'd force the LLM to write a join-less query with\nfilters, distincts, and aggregations. What happens if we normalize the tables step-by-step until we\nget to a well known form, such as ",(0,s.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Boyce%E2%80%93Codd_normal_form"},"Boyce-Codd Normal Form"),"? Do we consistently get better or worse accuracy?"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Important Future Work 2.2: Use of views.")," In relational modeling, views are an effective way to have higher\nand simpler modeling of your records. Similar to a ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," -","[LLM]","-> ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"P"),(0,s.kt)("mi",{parentName:"mrow"},"A"),(0,s.kt)("mi",{parentName:"mrow"},"R"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SPARQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.13889em"}},"SP"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"A"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"RQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," -","[Direct Mapping]","-> ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"SQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," pipeline,\none can test the effectiveness of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"N"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{NL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8778em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.10903em"}},"N"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," -","[LLM]","-> ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L"),(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mi",{parentName:"mrow"},"o"),(0,s.kt)("mi",{parentName:"mrow"},"v"),(0,s.kt)("mi",{parentName:"mrow"},"e"),(0,s.kt)("mi",{parentName:"mrow"},"r"),(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mi",{parentName:"mrow"},"V"),(0,s.kt)("mi",{parentName:"mrow"},"i"),(0,s.kt)("mi",{parentName:"mrow"},"e"),(0,s.kt)("mi",{parentName:"mrow"},"w"),(0,s.kt)("mi",{parentName:"mrow"},"s")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SQL-over-Views}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"SQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"),(0,s.kt)("span",{parentName:"span",className:"mbin mtight"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"o"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.03588em"}},"v"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.02778em"}},"er"),(0,s.kt)("span",{parentName:"span",className:"mbin mtight"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"Vi"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"e"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.02691em"}},"w"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"s"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," -","[Direct Mapping]","-> ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"Q"),(0,s.kt)("mrow",{parentName:"msub"},(0,s.kt)("mi",{parentName:"mrow"},"S"),(0,s.kt)("mi",{parentName:"mrow"},"Q"),(0,s.kt)("mi",{parentName:"mrow"},"L")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"Q_{SQL}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"Q"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3283em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"SQ"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal mtight"},"L"))))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.2861em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," pipeline."),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Important Future Work 3: Use of Cypher as intermediate query language to translate to SQL.")," One reason to experiment with Cypher\nin addition to SPARQL is that Cypher is, arguably, more similar to SQL than SPARQL but has the advantage that (common) join\nconditions are implicit in the ",(0,s.kt)("inlineCode",{parentName:"p"},"(a)-[e]->(b)")," node-arrow syntax. Yet Cypher does not have the verbosity of the SPARQL projections\nI mentioned above (so you project properties the same way you project columns in SQL). In my world, all high-level query languages\nlook very similar to SQL, so eventually when LLMs are smart enough, or even today, I think these language differences\nshould have minor effects. However, graph query languages will likely continue to have major advantages when writing\nrecursive queries, as they have specialized syntax (e.g., Cypher has the Kleene star syntax) to do so. For those queries,\nexpressing first in Cypher and then mapping to SQL could lead to an advantage. "),(0,s.kt)("h2",{id:"final-words"},"Final Words"),(0,s.kt)("p",null,"Needless to say, in the next few years, the field will be flooded with work on how to\nuse LLMs to solve the text-to-high-level-query problem. Many rules of thumb will emerge\nabout how to prompt them correctly. The questions one can ask in this space is endless.\nI can speculate about it a lot, but I think it's plausible that\nmany of these rules of thumb, specifically the syntactic\ndifferences in prompting, can become\nobsolete very quickly as newer and more advanced LLMs that are better at speaking high-level database languages emerge.\nFor example, it's plausible that people will stop showing LLMs example (question, query) pairs each time they ask them to generate\nSQL once LLMs are better at speaking SQL."),(0,s.kt)("p",null,"However, the harder question of how to model the data so that its meaning is clear, and the\nqueries that need to be written, are simpler, is more likely to remain a challenge for a longer time. I would not be too optimistic\nthat there can emerge very clear answers to this question. How to model your data is part-art and part-science.\nYet, some studiable questions, such as the effects of normalization, use of views or generating Cypher for recursive queries,\ncan yield some important best practices that can be useful to developers building these systems."),(0,s.kt)("p",null,"In the next post, I will cover what I learned about RAG over unstructured data. Graphs and knowledge graphs are playing\na more interesting role in that space. Until then, happy new year to all!"),(0,s.kt)("div",{className:"footnotes"},(0,s.kt)("hr",{parentName:"div"}),(0,s.kt)("ol",{parentName:"div"},(0,s.kt)("li",{parentName:"ol",id:"fn-1-a733ad"},"SPARQL syntax is different but a similar advantage exists by omitting type constraints.",(0,s.kt)("a",{parentName:"li",href:"#fnref-1-a733ad",className:"footnote-backref"},"\u21a9")))))}d.isMDXComponent=!0},6477:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/qa-over-enterprise-data-c63fb036791e4a0ec1f24d802d50254e.png"},2045:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/rag-using-structured-data-4e7c4e780c6a85b5664a3aa3f3f6c5a9.png"},4287:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/two-sql-generation-approaches-cceca4532513a6bb7ccae29e3f3ca94f.png"}}]);