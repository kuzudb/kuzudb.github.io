"use strict";(self.webpackChunkkuzu_docs=self.webpackChunkkuzu_docs||[]).push([[8482],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>f});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),u=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},c=function(e){var n=u(e.components);return a.createElement(s.Provider,{value:n},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(t),m=r,f=p["".concat(s,".").concat(m)]||p[m]||d[m]||i;return t?a.createElement(f,o(o({ref:n},c),{},{components:t})):a.createElement(f,o({ref:n},c))}));function f(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=m;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[p]="string"==typeof e?e:r,o[1]=l;for(var u=2;u<i;u++)o[u]=t[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},913:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var a=t(7462),r=(t(7294),t(3905));const i={title:"Scan",sidebar_position:11,description:"Direct scan over file"},o="Scan",l={unversionedId:"cypher/load_from",id:"cypher/load_from",title:"Scan",description:"Direct scan over file",source:"@site/docs/cypher/load_from.md",sourceDirName:"cypher",slug:"/cypher/load_from",permalink:"/docusaurus/cypher/load_from",draft:!1,tags:[],version:"current",sidebarPosition:11,frontMatter:{title:"Scan",sidebar_position:11,description:"Direct scan over file"},sidebar:"docSidebar",previous:{title:"Call",permalink:"/docusaurus/cypher/query-clauses/call"},next:{title:"Copy",permalink:"/docusaurus/cypher/copy"}},s={},u=[{value:"Example usage",id:"example-usage",level:2},{value:"Filtering/aggregating",id:"filteringaggregating",level:3},{value:"Create nodes from input file",id:"create-nodes-from-input-file",level:3},{value:"Reorder and subset columns",id:"reorder-and-subset-columns",level:3},{value:"Schema Information",id:"schema-information",level:2},{value:"CSV Detection",id:"csv-detection",level:3},{value:"Parquet Detection",id:"parquet-detection",level:3},{value:"Manually Specify",id:"manually-specify",level:3},{value:"Notes",id:"notes",level:4}],c={toc:u},p="wrapper";function d(e){let{components:n,...t}=e;return(0,r.kt)(p,(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"scan"},"Scan"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"LOAD FROM")," clause, which performs a direct scan over an input file without loading it into the database.\nThis clause can be useful when performing quick testing to extract a small sample of a larger file\nto load into a node table, or to perform simple transformation tasks like rearranging column order."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"LOAD FROM")," is designed to be used in the exact same way as ",(0,r.kt)("inlineCode",{parentName:"p"},"MATCH"),", meaning that it can be followed\nby arbitrary clauses like ",(0,r.kt)("inlineCode",{parentName:"p"},"WHERE, RETURN, CREATE, ..."),"."),(0,r.kt)("h2",{id:"example-usage"},"Example usage"),(0,r.kt)("p",null,"Some example usage is as follows."),(0,r.kt)("h3",{id:"filteringaggregating"},"Filtering/aggregating"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "user.csv" (header = true)\nWHERE to_int64(age) > 25 \nRETURN COUNT(*);\n----------------\n| COUNT_STAR() |\n----------------\n| 3            |\n----------------\n')),(0,r.kt)("h3",{id:"create-nodes-from-input-file"},"Create nodes from input file"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "user.csv" (header = true)\nCREATE (:User {name: name, age:to_int64(age)});\n\nMATCH (u:User) RETURN u;\n----------------------------------------------------\n| u                                                |\n----------------------------------------------------\n| {_ID: 0:0, _LABEL: User, name: Adam, age: 30}    |\n----------------------------------------------------\n| {_ID: 0:1, _LABEL: User, name: Karissa, age: 40} |\n----------------------------------------------------\n| {_ID: 0:2, _LABEL: User, name: Zhang, age: 50}   |\n----------------------------------------------------\n| {_ID: 0:3, _LABEL: User, name: Noura, age: 25}   |\n----------------------------------------------------\n')),(0,r.kt)("h3",{id:"reorder-and-subset-columns"},"Reorder and subset columns"),(0,r.kt)("p",null,"You can also use the scan functionality to reorder and subset columns from a given dataset. For\nexample, the following query will return just the ",(0,r.kt)("inlineCode",{parentName:"p"},"age")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"name")," in that order, even if the\ninput file has more columns specified in a different order."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "user.csv" (header = true)\nRETURN age, name LIMIT 3;\n\n--------------------\n| age | name       |\n--------------------\n| 30  | Adam       |\n--------------------\n| 40  | Karissa    |\n--------------------\n| 50  | Zhang      |\n--------------------\n')),(0,r.kt)("h2",{id:"schema-information"},"Schema Information"),(0,r.kt)("h3",{id:"csv-detection"},"CSV Detection"),(0,r.kt)("p",null,"When loading from a CSV file, user can specify the same set of configuration as ",(0,r.kt)("a",{parentName:"p",href:"/docusaurus/data-import/csv-import"},"importing from CSV through COPY"),"."),(0,r.kt)("p",null,"If no header information is available, K\xf9zu will use the default cofiguration and parse each column as ",(0,r.kt)("inlineCode",{parentName:"p"},"STRING")," type with name ",(0,r.kt)("inlineCode",{parentName:"p"},"column0, column1, ..."),". E.g."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "test.csv" RETURN *;\n-----------\n| column0 |\n-----------\n| a       |\n-----------\n| b       |\n-----------\n')),(0,r.kt)("p",null,"If header information is available in the file, K\xf9zu will parse the header and use data types and names as specified in the header. E.g."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "user.csv" (header = true) RETURN *;\n-----------------\n| name    | age |\n-----------------\n| Adam    | 30  |\n-----------------\n| Karissa | 40  |\n-----------------\n| Zhang   | 50  |\n-----------------\n| Noura   | 25  |\n-----------------\n')),(0,r.kt)("h3",{id:"parquet-detection"},"Parquet Detection"),(0,r.kt)("p",null,"Since parquet file contains schema, K\xf9zu will always use parquet schema information. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'LOAD FROM "user.parquet" RETURN *;\n----------------\n| f0      | f1 |\n----------------\n| Adam    | 30 |\n----------------\n| Karissa | 40 |\n----------------\n| Zhang   | 50 |\n----------------\n| Noura   | 25 |\n----------------\n')),(0,r.kt)("h3",{id:"manually-specify"},"Manually Specify"),(0,r.kt)("p",null,"To specify the schema information, user can use ",(0,r.kt)("inlineCode",{parentName:"p"},"LOAD WITH HEADERS (<name> <dataType>, ...) FROM ...")),(0,r.kt)("p",null,"E.g. the following query will bind first column to ",(0,r.kt)("inlineCode",{parentName:"p"},"name")," with STRING type and second column to ",(0,r.kt)("inlineCode",{parentName:"p"},"age")," with INT64 type."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"LOAD WITH HEADERS (name STRING, age INT64) FROM \"user.csv\" (header = true)\nWHERE name =~ 'Adam*'\nRETURN name, age;\n--------------\n| name | age |\n--------------\n| Adam | 30  |\n--------------\n")),(0,r.kt)("h4",{id:"notes"},"Notes"),(0,r.kt)("p",null,"If the header is specified manually"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"K\xf9zu will throw an exception if the given header does not the match number of columns in the file."),(0,r.kt)("li",{parentName:"ul"},"K\xf9zu will always try to cast to the type specified header. An exception will be thrown if the\ncasting operation fails.")))}d.isMDXComponent=!0}}]);